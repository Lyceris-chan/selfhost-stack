{
  "dashboard": "2026/01/17 06:14:23 [info] 22#22: *8 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:25 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:25 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:25 [info] 22#22: *10 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:27 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:27 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:27 [info] 22#22: *12 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:29 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:29 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:29 [info] 22#22: *14 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:31 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:31 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:31 [info] 22#22: *16 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:33 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n2026/01/17 06:14:33 [info] 22#22: *18 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:33 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:35 [info] 22#22: *20 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:35 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:35 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:37 [info] 22#22: *22 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:37 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:37 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:39 [info] 22#22: *24 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:39 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:39 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.0.72 - - [17/Jan/2026:06:14:41 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:41 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:41 [info] 22#22: *26 client 10.0.0.72 closed keepalive connection\n127.0.0.1 - - [17/Jan/2026:06:14:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:14:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n10.0.0.72 - - [17/Jan/2026:06:14:43 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n2026/01/17 06:14:43 [info] 22#22: *29 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:14:43 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.0.72 - - [17/Jan/2026:06:14:45 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:14:45 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:14:45 [info] 22#22: *31 client 10.0.0.72 closed keepalive connection\n127.0.0.1 - - [17/Jan/2026:06:15:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:15:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n127.0.0.1 - - [17/Jan/2026:06:15:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:15:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n127.0.0.1 - - [17/Jan/2026:06:16:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:16:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n127.0.0.1 - - [17/Jan/2026:06:16:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:16:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n127.0.0.1 - - [17/Jan/2026:06:17:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:17:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n127.0.0.1 - - [17/Jan/2026:06:17:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:17:42 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n127.0.0.1 - - [17/Jan/2026:06:18:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:18:12 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n",
  "api": "INFO:     Uvicorn running on http://0.0.0.0:55555 (Press CTRL+C to quit)\nINFO:     127.0.0.1:54638 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:35422 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:44286 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:55712 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:42072 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:60398 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:52956 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:60210 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:43372 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:40868 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:37084 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:40098 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:57158 - \"GET /api/health HTTP/1.1\" 200 OK\n[INFO] Watchtower Notification (Plain): Watchtower 1.7.1\nUsing notifications: generic+http\nChecking all containers (except explicitly disabled with label)\nScheduling first run: 2026-01-17 07:13:42 +0000 UTC\nNote that the first check will be performed in 59 minutes, 59 seconds\n\nINFO:     172.18.0.4:41236 - \"POST /watchtower?token=dyYniC2GCEVnestrwZYvPcSXfQ5JdDIP HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51744 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:59246 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.8:52544 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:52552 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:52560 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:52576 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:57114 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:57124 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:57138 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:57148 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:57154 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:45186 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.8:56746 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:56750 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:56756 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:56772 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:56776 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:39006 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:47614 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:33694 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:40372 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51620 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:45522 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:53448 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:57396 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:48354 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:56256 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:48532 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:37890 - \"GET /api/health HTTP/1.1\" 200 OK\n",
  "adguard": "2026/01/17 06:09:03.641226 [info] starting adguard home version=\"AdGuard Home, version v0.107.71\"\n2026/01/17 06:09:03.641804 [info] config_migrator: upgrade yaml from=29 to=30\n2026/01/17 06:09:03.641821 [info] config_migrator: upgrade yaml from=30 to=31\n2026/01/17 06:09:03.641827 [info] config_migrator: upgrade yaml from=31 to=32\n2026/01/17 06:09:03.652334 [info] dhcpd: warning: creating dhcpv4 server err=\"dhcpv4: invalid IP is not an IPv4 address\"\n2026/01/17 06:09:03.657762 [info] tls_manager: using default ciphers\n2026/01/17 06:09:03.657950 [info] tls_manager: parsing multiple pem certificates num=1\n2026/01/17 06:09:03.742086 [info] webapi: initializing\n2026/01/17 06:09:03.746068 [info] warning: private rdns resolution failed; disabling err=\"preparing resolvers: no upstream specified\"\n2026/01/17 06:09:03.746129 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/17 06:09:03.746140 [info] dnsproxy: cache enabled size=4096\n2026/01/17 06:09:03.746150 [info] dnsproxy: max goroutines is set count=300\n2026/01/17 06:09:03.746191 [info] dnsproxy: ratelimit is enabled rps=20 ipv4_subnet_mask_len=24 ipv6_subnet_mask_len=56\n2026/01/17 06:09:03.746199 [info] dnsproxy: server will refuse requests of type any\n2026/01/17 06:09:03.746206 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/17 06:09:03.746212 [info] dnsproxy: cache enabled size=4194304\n2026/01/17 06:09:03.746221 [info] dnsproxy: max goroutines is set count=300\n2026/01/17 06:09:03.747277 [info] addrproc: processing addresses\n2026/01/17 06:09:03.747956 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work\n2026/01/17 06:09:03.749445 [info] permcheck: changed permissions type=file path=/opt/adguardhome/conf/AdGuardHome.yaml\n2026/01/17 06:09:03.749555 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data\n2026/01/17 06:09:03.749604 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data/filters\n2026/01/17 06:09:03.749708 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/sessions.db\n2026/01/17 06:09:03.749844 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/stats.db\n2026/01/17 06:09:03.750003 [info] webapi: AdGuard Home is available at the following addresses:\n2026/01/17 06:09:03.750285 [info] go to http://127.0.0.1:8083\n2026/01/17 06:09:03.750344 [info] go to http://[::1]:8083\n2026/01/17 06:09:03.750370 [info] go to http://172.20.0.2:8083\n2026/01/17 06:09:03.750915 [info] starting plain server server=plain addr=0.0.0.0:8083\n2026/01/17 06:09:03.751281 [info] go to https://10.0.0.72:443\n2026/01/17 06:09:03.751354 [info] starting https server server=https\n2026/01/17 06:09:03.753979 [info] dnsproxy: starting dns proxy server\n2026/01/17 06:09:03.754087 [info] dnsproxy: creating udp server socket addr=0.0.0.0:53\n2026/01/17 06:09:03.754238 [info] dnsproxy: listening to udp addr=[::]:53\n2026/01/17 06:09:03.754279 [info] dnsproxy: creating tcp server socket addr=0.0.0.0:53\n2026/01/17 06:09:03.754366 [info] dnsproxy: listening to tcp addr=[::]:53\n2026/01/17 06:09:03.754419 [info] dnsproxy: creating tls server socket addr=0.0.0.0:853\n2026/01/17 06:09:03.754470 [info] dnsproxy: listening to tls addr=[::]:853\n2026/01/17 06:09:03.754528 [info] dnsproxy: creating quic listener addr=0.0.0.0:853\n2026/01/17 06:09:03.754659 failed to sufficiently increase receive buffer size (was: 1024 kiB, wanted: 7168 kiB, got: 2048 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n2026/01/17 06:09:03.754997 [info] dnsproxy: listening quic addr=[::]:853\n2026/01/17 06:09:03.755135 [info] dnsproxy: entering listener loop proto=tcp addr=[::]:53\n2026/01/17 06:09:03.755302 [info] dnsproxy: entering udp listener loop addr=[::]:53\n2026/01/17 06:09:03.755475 [info] dnsproxy: entering listener loop proto=tls addr=[::]:853\n2026/01/17 06:09:03.755577 [info] dnsproxy: entering dns-over-quic listener loop addr=[::]:853\n2026/01/17 06:09:23.884336 [info] filtering: saving contents id=1 path=/opt/adguardhome/work/data/filters/1.txt\n2026/01/17 06:09:24.136012 [info] filtering: filter updated id=1 bytes_written=40496482 rules_count=2001416\n2026/01/17 06:09:24.136038 [info] filtering: updated filter id=1 rules_count=2001416 prev_rules_count=0\n",
  "invidious": "[production] Invidious is ready to lead at http://0.0.0.0:3000\n2026-01-17 06:14:01 UTC [info] jobs: running ClearExpiredItems job\nUnhandled exception in spawn: Hostname lookup for api.invidious.io failed: Try again (Socket::Addrinfo::Error)\n  from /usr/share/crystal/src/crystal/system/unix/addrinfo.cr:59:7 in 'getaddrinfo'\n  from /usr/share/crystal/src/crystal/system/addrinfo.cr:18:13 in 'io'\n  from /usr/share/crystal/src/http/client.cr:670:19 in 'send_request'\n  from /usr/share/crystal/src/http/client.cr:602:37 in 'exec_internal_single'\n  from /usr/share/crystal/src/http/client.cr:584:18 in 'exec'\n  from src/invidious/jobs/instance_refresh_job.cr:70:38 in 'begin'\n  from src/invidious/jobs.cr:37:15 in '->'\n  from /usr/share/crystal/src/fiber.cr:170:11 in 'run'\n  from ???\n2026-01-17 06:14:04 UTC [info] jobs: ClearExpiredItems done.\n2026-01-17 06:14:31 UTC [info] 200 GET /api/v1/stats 6.66ms\n2026-01-17 06:15:01 UTC [info] 200 GET /api/v1/stats 84.09Âµs\n2026-01-17 06:15:31 UTC [info] 200 GET /api/v1/stats 75.97Âµs\n2026-01-17 06:16:01 UTC [info] 200 GET /api/v1/stats 83.56Âµs\n2026-01-17 06:16:31 UTC [info] 200 GET /api/v1/stats 78.04Âµs\n2026-01-17 06:17:01 UTC [info] 200 GET /api/v1/stats 78.95Âµs\n2026-01-17 06:17:31 UTC [info] 200 GET /api/v1/stats 88.21Âµs\n2026-01-17 06:18:01 UTC [info] 200 GET /api/v1/stats 73.98Âµs\n",
  "breezewiki": "note: config file not detected, using defaults\nnote: 1 items loaded from environment variables\nYour Web application is running at http://localhost:10416.\nStop this program at any time to terminate the Web Server.\n",
  "redlib": " ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client (mobile + generic)\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client (mobile + generic)\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client (mobile + generic)\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client (mobile + generic)\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client (mobile + generic)\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n ERROR redlib::oauth > [â›”] Failed to create OAuth client: error trying to connect: dns error: failed to lookup address information: Try again. Retrying in 5 seconds...\n",
  "scribe": "{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:14:41Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"290edf00-163e-4b7e-ad8e-3c230e7e6c8b\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:14:41Z\",\"local\":{\"status\":200,\"duration\":\"24.56ms\",\"request_id\":\"290edf00-163e-4b7e-ad8e-3c230e7e6c8b\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:15:41Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"cd8b86d0-d857-4bfb-a7e1-583009aad68d\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:15:41Z\",\"local\":{\"status\":200,\"duration\":\"138.77Âµs\",\"request_id\":\"cd8b86d0-d857-4bfb-a7e1-583009aad68d\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:16:41Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"97f5fd20-1159-43cc-bfe8-82896e5c0921\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:16:41Z\",\"local\":{\"status\":200,\"duration\":\"207.7Âµs\",\"request_id\":\"97f5fd20-1159-43cc-bfe8-82896e5c0921\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:17:41Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"8ed4b083-9185-4618-830d-bb9efc5add46\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:17:41Z\",\"local\":{\"status\":200,\"duration\":\"347.11Âµs\",\"request_id\":\"8ed4b083-9185-4618-830d-bb9efc5add46\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:18:41Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"c97782bb-87b4-428a-977f-055ec34c66ca\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:18:41Z\",\"local\":{\"status\":200,\"duration\":\"143.82Âµs\",\"request_id\":\"c97782bb-87b4-428a-977f-055ec34c66ca\"}}\n",
  "anonymousoverflow": "",
  "searxng": "  File \"/usr/local/searxng/searx/network/network.py\", line 300, in call_client\n    raise e\n  File \"/usr/local/searxng/searx/network/network.py\", line 285, in call_client\n    response = await client.request(method, url, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/searxng/.venv/lib/python3.14/site-packages/httpx/_client.py\", line 1540, in request\n    return await self.send(request, auth=auth, follow_redirects=follow_redirects)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/searxng/.venv/lib/python3.14/site-packages/httpx/_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n  File \"/usr/local/searxng/.venv/lib/python3.14/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/usr/local/searxng/.venv/lib/python3.14/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/searxng/.venv/lib/python3.14/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/searxng/.venv/lib/python3.14/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n         ~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/usr/lib/python3.14/contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n  File \"/usr/local/searxng/.venv/lib/python3.14/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno -3] Temporary failure in name resolution\n2026-01-17 06:14:15,517 ERROR:searx.searx.search.processor: Init method of engine radio browser failed due to an exception.\nTraceback (most recent call last):\n  File \"/usr/local/searxng/searx/search/processors/abstract.py\", line 155, in init_engine\n    init_ok = self.engine.init(eng_setting)\n  File \"/usr/local/searxng/searx/engines/radio_browser.py\", line 62, in init\n    server_list()\n    ~~~~~~~~~~~^^\n  File \"/usr/local/searxng/searx/engines/radio_browser.py\", line 72, in server_list\n    ips = socket.getaddrinfo(\"all.api.radio-browser.info\", 80, 0, 0, socket.IPPROTO_TCP)\n  File \"/usr/lib/python3.14/socket.py\", line 983, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno -3] Temporary failure in name resolution\n2026-01-17 06:14:15,567 ERROR:searx.search.processors: can't register engine processor: wikidata (init failed)\n2026-01-17 06:14:15,571 ERROR:searx.search.processors: can't register engine processor: radio browser (init failed)\n",
  "rimgo": "\n â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” \n â”‚                  Fiber v2.52.10                   â”‚ \n â”‚               http://127.0.0.1:3002               â”‚ \n â”‚       (bound on host 0.0.0.0 and port 3002)       â”‚ \n â”‚                                                   â”‚ \n â”‚ Handlers ............ 57  Processes ........... 1 â”‚ \n â”‚ Prefork ....... Disabled  PID ................. 1 â”‚ \n â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ \n\n",
  "cobalt": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/17 06:13:42 [notice] 1#1: using the \"epoll\" event method\n2026/01/17 06:13:42 [notice] 1#1: nginx/1.29.4\n2026/01/17 06:13:42 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/17 06:13:42 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/17 06:13:42 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/17 06:13:42 [notice] 1#1: start worker processes\n2026/01/17 06:13:42 [notice] 1#1: start worker process 30\n2026/01/17 06:13:42 [notice] 1#1: start worker process 31\n2026/01/17 06:13:42 [notice] 1#1: start worker process 32\n2026/01/17 06:13:42 [notice] 1#1: start worker process 33\n",
  "memos": "2026/01/17 06:13:42 WARN failed to find migration history in pre-migrate error=\"SQL logic error: no such table: migration_history (1)\"\n---\nServer profile\nversion: 0.24.0\ndata: /var/opt/memos\ndsn: /var/opt/memos/memos_prod.db\naddr: \nport: 5230\nmode: prod\ndriver: sqlite\n---\nVersion 0.24.0 has been started on port 5230\n---\nSee more in:\nðŸ‘‰Website: https://usememos.com\nðŸ‘‰GitHub: https://github.com/usememos/memos\n---\n\nâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•\nâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘\nâ–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘\nâ•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•\n",
  "portainer": "\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[31mWRN\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cli/cli.go:168\u001b[0m\u001b[36m >\u001b[0m the --no-analytics flag has been kept to allow migration of instances running a previous version of Portainer with this flag enabled, to version 2.0 where enabling this flag will have no effect |\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:325\u001b[0m\u001b[36m >\u001b[0m encryption key file not present | \u001b[36mfilename=\u001b[0m/run/secrets/portainer\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:365\u001b[0m\u001b[36m >\u001b[0m proceeding without encryption key |\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/database/boltdb/db.go:137\u001b[0m\u001b[36m >\u001b[0m loading PortainerDB | \u001b[36mfilename=\u001b[0mportainer.db\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/internal/ssl/ssl.go:79\u001b[0m\u001b[36m >\u001b[0m no cert files found, generating self signed SSL certificates |\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:507\u001b[0m\u001b[36m >\u001b[0m created admin user with the given password. |\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/chisel/service.go:228\u001b[0m\u001b[36m >\u001b[0m generated a new Chisel private key file | \u001b[36mprivate-key=\u001b[0m/data/chisel/private-key.pem\n2026/01/17 06:13:44 server: Reverse tunnelling enabled\n2026/01/17 06:13:44 server: Fingerprint HeLMyHgDykDZd+6cohIAxdCgJXoR/I23RKygnzXqNKw=\n2026/01/17 06:13:44 server: Listening on http://0.0.0.0:8000\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:636\u001b[0m\u001b[36m >\u001b[0m starting Portainer | \u001b[36mbuild_number=\u001b[0m251 \u001b[36mgo_version=\u001b[0m1.24.11 \u001b[36mimage_tag=\u001b[0m2.33.6-linux-amd64 \u001b[36mnodejs_version=\u001b[0m18.20.8 \u001b[36mversion=\u001b[0m2.33.6 \u001b[36mwebpack_version=\u001b[0m5.88.2 \u001b[36myarn_version=\u001b[0m1.22.22\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:351\u001b[0m\u001b[36m >\u001b[0m starting HTTP server | \u001b[36mbind_address=\u001b[0m:9000\n\u001b[90m2026/01/17 06:13AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:367\u001b[0m\u001b[36m >\u001b[0m starting HTTPS server | \u001b[36mbind_address=\u001b[0m:9443\n",
  "wg-easy": "2026-01-17T06:09:03.568Z Server Listening on http://0.0.0.0:51821\n2026-01-17T06:09:03.576Z WireGuard Loading configuration...\n$ wg genkey\n$ echo ***hidden*** | wg pubkey\n2026-01-17T06:09:03.614Z WireGuard Configuration generated.\n2026-01-17T06:09:03.615Z WireGuard Config saving...\n2026-01-17T06:09:03.616Z WireGuard Config saved.\n$ wg-quick down wg0\n$ wg-quick up wg0\n2026-01-17T06:09:03.838Z WireGuard Config syncing...\n$ wg syncconf wg0 <(wg-quick strip wg0)\n2026-01-17T06:09:03.871Z WireGuard Config synced.\n",
  "odido-booster": "INFO:odido.service:Service initialized\n/app/app/main.py:43: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"startup\")\n/app/app/main.py:48: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"shutdown\")\nINFO:odido.service:Odido API not configured - skipping remaining data sync\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nINFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8085 (Press CTRL+C to quit)\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:All renewal attempts failed - check Odido API credentials and network connectivity\nINFO:     127.0.0.1:54918 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:55142 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:39684 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51900 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:58496 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:53560 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:35760 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:33678 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:54386 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:44786 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:46584 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:37368 - \"GET /docs HTTP/1.1\" 200 OK\n",
  "vert": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: /etc/nginx/conf.d/default.conf differs from the packaged version\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/17 06:14:17 [notice] 1#1: using the \"epoll\" event method\n2026/01/17 06:14:17 [notice] 1#1: nginx/1.28.1\n2026/01/17 06:14:17 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/17 06:14:17 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/17 06:14:17 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/17 06:14:17 [notice] 1#1: start worker processes\n2026/01/17 06:14:17 [notice] 1#1: start worker process 28\n2026/01/17 06:14:17 [notice] 1#1: start worker process 29\n2026/01/17 06:14:17 [notice] 1#1: start worker process 30\n2026/01/17 06:14:17 [notice] 1#1: start worker process 31\n127.0.0.1 - - [17/Jan/2026:06:14:22 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:14:52 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:15:22 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:15:52 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:16:22 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:16:52 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:17:22 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:17:52 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:18:22 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:18:52 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:19:23 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:19:53 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n",
  "immich": "\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:40 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MetadataService]\u001b[39m \u001b[32mInitialized local reverse geocoder\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:40 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mPlugin immich-core is up to date (version 2.0.0). Skipping\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:40 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully processed core plugin: immich-core (version 2.0.0)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:40 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully loaded plugin: immich-core\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:40 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:ServerService]\u001b[39m \u001b[32mFeature Flags: {\n  \"smartSearch\": true,\n  \"facialRecognition\": true,\n  \"duplicateDetection\": true,\n  \"map\": true,\n  \"reverseGeocoding\": true,\n  \"importFaces\": false,\n  \"sidecar\": true,\n  \"search\": true,\n  \"trash\": true,\n  \"oauth\": false,\n  \"oauthAutoLaunch\": false,\n  \"ocr\": true,\n  \"passwordLogin\": true,\n  \"configFile\": false,\n  \"email\": false\n}\u001b[39m\n\u001b[33m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[33m   WARN\u001b[39m \u001b[33m[Microservices:VersionService]\u001b[39m \u001b[33mUnable to run version check: Error: Failed to fetch GitHub release: TypeError: fetch failed\nError: Failed to fetch GitHub release: TypeError: fetch failed\n    at ServerInfoRepository.getGitHubRelease (/usr/src/app/server/dist/repositories/server-info.repository.js:60:19)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async VersionService.handleVersionCheck (/usr/src/app/server/dist/services/version.service.js:111:77)\n    at async VersionService.onBootstrap (/usr/src/app/server/dist/services/version.service.js:64:9)\n    at async EventRepository.onEvent (/usr/src/app/server/dist/repositories/event.repository.js:91:13)\n    at async MicroservicesModule.onModuleInit (/usr/src/app/server/dist/app.module.js:90:9)\n    at async callModuleInitHook (/usr/src/app/server/node_modules/.pnpm/@nestjs+core@11.1.9_@nestjs+common@11.1.9_class-transformer@0.5.1_class-validator@0.14._89e063bd3a6d5071b082cab065bf34d7/node_modules/@nestjs/core/hooks/on-module-init.hook.js:51:9)\n    at async NestApplication.callInitHook (/usr/src/app/server/node_modules/.pnpm/@nestjs+core@11.1.9_@nestjs+common@11.1.9_class-transformer@0.5.1_class-validator@0.14._89e063bd3a6d5071b082cab065bf34d7/node_modules/@nestjs/core/nest-application-context.js:242:13)\n    at async NestApplication.init (/usr/src/app/server/node_modules/.pnpm/@nestjs+core@11.1.9_@nestjs+common@11.1.9_class-transformer@0.5.1_class-validator@0.14._89e063bd3a6d5071b082cab065bf34d7/node_modules/@nestjs/core/nest-application.js:103:9)\n    at async NestApplication.listen (/usr/src/app/server/node_modules/.pnpm/@nestjs+core@11.1.9_@nestjs+common@11.1.9_class-transformer@0.5.1_class-validator@0.14._89e063bd3a6d5071b082cab065bf34d7/node_modules/@nestjs/core/nest-application.js:175:13)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:SystemConfigService]\u001b[39m \u001b[32mLogLevel=log (set via system config)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MachineLearningRepository]\u001b[39m \u001b[32mMachine learning server became healthy (http://127.0.0.1:3003).\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestFactory]\u001b[39m \u001b[32mStarting Nest application...\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsCommonModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyCoreModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mDiscoveryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryCoreModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsRootModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mMicroservicesModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestApplication]\u001b[39m \u001b[32mNest application successfully started\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:14:50 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:Bootstrap]\u001b[39m \u001b[32mImmich Microservices is running [v2.4.1] [production] \u001b[39m\n",
  "wikiless": "Wikiless 10.0.0.72:8180 running on http://0.0.0.0:8180\nCleared cached static media files. You can turn this off by setting the config.cache_control to false.\nDownload error for https://en.wikipedia.org/?useskin=vector: EAI_AGAIN\nInvalid wiki_html.\nDownload error for https://en.wikipedia.org/?useskin=vector: EAI_AGAIN\nInvalid wiki_html.\nInvalid wiki_html.\nDownload error for https://en.wikipedia.org/?useskin=vector: ETIMEDOUT\nInvalid wiki_html.\nDownload error for https://en.wikipedia.org/?useskin=vector: ETIMEDOUT\nDownload error for https://en.wikipedia.org/?useskin=vector: EAI_AGAIN\nInvalid wiki_html.\nDownload error for https://en.wikipedia.org/?useskin=vector: EAI_AGAIN\nInvalid wiki_html.\nDownload error for https://en.wikipedia.org/?useskin=vector: EAI_AGAIN\nInvalid wiki_html.\nDownload error for https://en.wikipedia.org/?useskin=vector: EAI_AGAIN\nInvalid wiki_html.\nDownload error for https://en.wikipedia.org/?useskin=vector: EAI_AGAIN\nInvalid wiki_html.\n",
  "unbound": "[1768630143] unbound[1:0] warning: so-sndbuf 4194304 was not granted. Got 425984. To fix: start with root permissions(linux) or sysctl bigger net.core.wmem_max(linux) or kern.ipc.maxsockbuf(bsd) values. or set so-sndbuf: 0 (use system value).\n",
  "gluetun": "2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 8080 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 8081 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 8085 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 8180 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 3000 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 3002 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 8280 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 8480 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 80 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 24153 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 8282 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 9000 through interface tun0...\n2026-01-17T06:20:41Z INFO [firewall] setting allowed input port 2283 through interface tun0...\n2026-01-17T06:20:47Z WARN [vpn] restarting VPN because it failed to pass the healthcheck: startup check: all check tries failed: parallel attempt 1/1 failed: dialing: dial tcp4: lookup github.com: i/o timeout\n2026-01-17T06:20:47Z INFO [vpn] ðŸ‘‰ See https://github.com/qdm12/gluetun-wiki/blob/main/faq/healthcheck.md\n2026-01-17T06:20:47Z INFO [vpn] DO NOT OPEN AN ISSUE UNLESS YOU HAVE READ AND TRIED EVERY POSSIBLE SOLUTION\n2026-01-17T06:20:47Z INFO [vpn] stopping\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 10416...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 8080...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 8081...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 8085...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 8180...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 3000...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 3002...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 8280...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 8480...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 80...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 24153...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 8282...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 9000...\n2026-01-17T06:20:47Z INFO [firewall] removing allowed port 2283...\n2026-01-17T06:20:47Z INFO [vpn] starting\n2026-01-17T06:20:47Z INFO [firewall] allowing VPN connection...\n2026-01-17T06:20:47Z INFO [wireguard] Using available kernelspace implementation\n2026-01-17T06:20:47Z INFO [wireguard] Connecting to 80.79.7.101:51820\n2026-01-17T06:20:47Z INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 10416 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 8080 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 8081 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 8085 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 8180 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 3000 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 3002 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 8280 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 8480 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 80 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 24153 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 8282 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 9000 through interface tun0...\n2026-01-17T06:20:48Z INFO [firewall] setting allowed input port 2283 through interface tun0...\n",
  "companion": "    at async fetch (ext:deno_fetch/26_fetch.js:475:11)\n    at async HTTPClient.fetch (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/utils/HTTPClient.ts:141:22)\n    at async Actions.execute (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/core/Actions.ts:154:22)\n    at async setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:178:31)\n    at async onmessage (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:99:21)\n}\nException in cron handler regenerate youtube session TypeError: error sending request for url (https://www.youtube.com/youtubei/v1/att/get?prettyPrint=false&alt=json): client error (Connect): dns error: failed to lookup address information: Temporary failure in name resolution\n    at async mainFetch (ext:deno_fetch/26_fetch.js:192:12)\n    at async fetch (ext:deno_fetch/26_fetch.js:475:11)\n    at async HTTPClient.fetch (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/utils/HTTPClient.ts:141:22)\n    at async Actions.execute (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/core/Actions.ts:154:22)\n    at async setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:178:31)\n    at async onmessage (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:99:21)\n{\n  errorFromWorker: TypeError: error sending request for url (https://www.youtube.com/youtubei/v1/att/get?prettyPrint=false&alt=json): client error (Connect): dns error: failed to lookup address information: Temporary failure in name resolution\n    at async mainFetch (ext:deno_fetch/26_fetch.js:192:12)\n    at async fetch (ext:deno_fetch/26_fetch.js:475:11)\n    at async HTTPClient.fetch (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/utils/HTTPClient.ts:141:22)\n    at async Actions.execute (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/core/Actions.ts:154:22)\n    at async setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:178:31)\n    at async onmessage (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:99:21)\n}\n[ERROR] Failed to initialize PO token: RetryError: Retrying exceeded the maxAttempts (5).\n    at retry (https://jsr.io/@std/async/1.0.11/retry.ts:154:15)\n    at eventLoopTick (ext:core/01_core.js:187:7)\nCaused by TypeError: error sending request for url (https://www.youtube.com/youtubei/v1/att/get?prettyPrint=false&alt=json): client error (Connect): dns error: failed to lookup address information: Temporary failure in name resolution\n    at async mainFetch (ext:deno_fetch/26_fetch.js:192:12)\n    at async fetch (ext:deno_fetch/26_fetch.js:475:11)\n    at async HTTPClient.fetch (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/utils/HTTPClient.ts:141:22)\n    at async Actions.execute (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/core/Actions.ts:154:22)\n    at async setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:178:31)\n    at async onmessage (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:99:21) {\n  name: \"RetryError\"\n}\n{\n  errorFromWorker: TypeError: error sending request for url (https://www.youtube.com/youtubei/v1/att/get?prettyPrint=false&alt=json): client error (Connect): dns error: failed to lookup address information: Temporary failure in name resolution\n    at async mainFetch (ext:deno_fetch/26_fetch.js:192:12)\n    at async fetch (ext:deno_fetch/26_fetch.js:475:11)\n    at async HTTPClient.fetch (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/utils/HTTPClient.ts:141:22)\n    at async Actions.execute (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/core/Actions.ts:154:22)\n    at async setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:178:31)\n    at async onmessage (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:99:21)\nException in cron handler regenerate youtube session TypeError: error sending request for url (https://www.youtube.com/youtubei/v1/att/get?prettyPrint=false&alt=json): client error (Connect): dns error: failed to lookup address information: Temporary failure in name resolution\n    at async mainFetch (ext:deno_fetch/26_fetch.js:192:12)\n}\n    at async fetch (ext:deno_fetch/26_fetch.js:475:11)\n    at async HTTPClient.fetch (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/utils/HTTPClient.ts:141:22)\n    at async Actions.execute (https://cdn.jsdelivr.net/gh/LuanRT/YouTube.js@v16.0.0-deno/deno/src/core/Actions.ts:154:22)\n    at async setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:178:31)\n    at async onmessage (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:99:21)\n",
  "vertd": "[2026-01-17T06:13:40Z INFO  vertd] starting vertd\n[2026-01-17T06:13:47Z INFO  vertd] working w/ ffmpeg 6.1.1-3ubuntu5 and ffprobe 6.1.1-3ubuntu5\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] *******\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] you're running vertd on a docker container, but no GPU was detected.\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] this usually is because you're running Docker under WSL or because\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] you are not passing the GPU device correctly.\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] \n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] if this doesn't seem right, make sure to provide the following info when\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] asking for help:\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] - adapter name: llvmpipe (LLVM 20.1.2, 256 bits)\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] - adapter vendor: 0x10005\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] - backend: vulkan\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] - device ID: 0\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] - device type: Cpu\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] - driver: llvmpipe\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] - driver info: Mesa 25.0.7-0ubuntu0.24.04.2 (LLVM 20.1.2)\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] \n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] vertd will fall back to CPU rendering to ensure conversions can still proceed.\n[2026-01-17T06:13:49Z WARN  vertd::converter::gpu] *******\n[2026-01-17T06:13:49Z INFO  vertd] using CPU rendering (software encoding) -- this will be slower than GPU acceleration\n[2026-01-17T06:13:50Z INFO  vertd::http] http server listening on 0.0.0.0:24153\n",
  "watchtower": "time=\"2026-01-17T06:13:42Z\" level=info msg=\"Watchtower 1.7.1\"\ntime=\"2026-01-17T06:13:42Z\" level=info msg=\"Using notifications: generic+http\"\ntime=\"2026-01-17T06:13:42Z\" level=info msg=\"Checking all containers (except explicitly disabled with label)\"\ntime=\"2026-01-17T06:13:42Z\" level=info msg=\"Scheduling first run: 2026-01-17 07:13:42 +0000 UTC\"\ntime=\"2026-01-17T06:13:42Z\" level=info msg=\"Note that the first check will be performed in 59 minutes, 59 seconds\"\n",
  "invidious-db": "2026-01-17 06:13:49.227 UTC [48] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init-invidious-db.sh\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE TYPE\nCREATE TABLE\nGRANT\nCREATE TABLE\nGRANT\n\nwaiting for server to shut down...2026-01-17 06:13:50.922 UTC [48] LOG:  received fast shutdown request\n.2026-01-17 06:13:50.925 UTC [48] LOG:  aborting any active transactions\n2026-01-17 06:13:50.929 UTC [48] LOG:  background worker \"logical replication launcher\" (PID 55) exited with exit code 1\n2026-01-17 06:13:50.930 UTC [50] LOG:  shutting down\n2026-01-17 06:13:50.968 UTC [88] FATAL:  the database system is shutting down\n2026-01-17 06:13:50.997 UTC [48] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-17 06:13:51.052 UTC [1] LOG:  starting PostgreSQL 14.20 (Debian 14.20-1.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n2026-01-17 06:13:51.052 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-17 06:13:51.052 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-17 06:13:51.055 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-17 06:13:51.061 UTC [90] LOG:  database system was shut down at 2026-01-17 06:13:50 UTC\n2026-01-17 06:13:51.068 UTC [1] LOG:  database system is ready to accept connections\n",
  "wikiless-redis": "1:C 17 Jan 2026 06:13:41.283 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 17 Jan 2026 06:13:41.283 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 17 Jan 2026 06:13:41.283 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 17 Jan 2026 06:13:41.283 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 17 Jan 2026 06:13:41.285 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 17 Jan 2026 06:13:41.285 * monotonic clock: POSIX clock_gettime\n1:M 17 Jan 2026 06:13:41.287 * Running mode=standalone, port=6379.\n1:M 17 Jan 2026 06:13:41.288 * Server initialized\n1:M 17 Jan 2026 06:13:41.288 * Ready to accept connections tcp\n",
  "searxng-redis": "1:C 17 Jan 2026 06:13:41.117 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 17 Jan 2026 06:13:41.120 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 17 Jan 2026 06:13:41.120 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 17 Jan 2026 06:13:41.120 * Configuration loaded\n1:M 17 Jan 2026 06:13:41.122 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 17 Jan 2026 06:13:41.122 * monotonic clock: POSIX clock_gettime\n1:M 17 Jan 2026 06:13:41.129 * Running mode=standalone, port=6379.\n1:M 17 Jan 2026 06:13:41.129 * Server initialized\n1:M 17 Jan 2026 06:13:41.135 * Ready to accept connections tcp\n",
  "immich-db": "selecting default shared_buffers ... 128MB\nselecting default time zone ... Etc/UTC\ncreating configuration files ... ok\nrunning bootstrap script ... ok\nperforming post-bootstrap initialization ... ok\nsyncing data to disk ... ok\n\n\nSuccess. You can now start the database server using:\n\n    pg_ctl -D /var/lib/postgresql/data -l logfile start\n\ninitdb: warning: enabling \"trust\" authentication for local connections\nYou can change this by editing pg_hba.conf or using the option -A, or\n--auth-local and --auth-host, the next time you run initdb.\n2026-01-17 06:13:49.101 GMT [55] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:13:49.104 GMT [55] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\nwaiting for server to start....2026-01-17 06:13:49.157 GMT [60] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:13:49.158 GMT [60] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:13:49.347 UTC [60] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-17 06:13:49.356 UTC [60] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-17 06:13:49.401 UTC [61] LOG:  database system was shut down at 2026-01-17 06:13:46 UTC\n2026-01-17 06:13:49.426 UTC [60] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*\n\nwaiting for server to shut down....2026-01-17 06:13:50.249 UTC [60] LOG:  received fast shutdown request\n2026-01-17 06:13:50.250 UTC [60] LOG:  aborting any active transactions\n2026-01-17 06:13:50.255 UTC [60] LOG:  background worker \"logical replication launcher\" (PID 68) exited with exit code 1\n2026-01-17 06:13:50.255 UTC [63] LOG:  shutting down\n2026-01-17 06:13:50.296 UTC [60] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-17 06:13:50.374 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:13:50.375 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:13:50.436 UTC [1] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-17 06:13:50.437 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-17 06:13:50.437 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-17 06:13:50.449 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-17 06:13:50.456 UTC [78] LOG:  database system was shut down at 2026-01-17 06:13:50 UTC\n2026-01-17 06:13:50.467 UTC [1] LOG:  database system is ready to accept connections\n2026-01-17 06:13:59.943 UTC [96] ERROR:  relation \"system_metadata\" does not exist at character 21\n2026-01-17 06:13:59.943 UTC [96] STATEMENT:  select \"value\" from \"system_metadata\" where \"key\" = $1\n",
  "immich-redis": "1:M 17 Jan 2026 06:13:41.271 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:M 17 Jan 2026 06:13:41.276 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo\n1:M 17 Jan 2026 06:13:41.276 * Valkey version=9.0.1, bits=64, commit=00000000, modified=0, pid=1, just started\n1:M 17 Jan 2026 06:13:41.276 # Warning: no config file specified, using the default config. In order to specify a config file use valkey-server /path/to/valkey.conf\n1:M 17 Jan 2026 06:13:41.277 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 17 Jan 2026 06:13:41.278 * monotonic clock: POSIX clock_gettime\n1:M 17 Jan 2026 06:13:41.280 * Running mode=standalone, port=6379.\n1:M 17 Jan 2026 06:13:41.284 * Server initialized\n1:M 17 Jan 2026 06:13:41.300 * Ready to accept connections tcp\n1:M 17 Jan 2026 06:18:42.042 * 100 changes in 300 seconds. Saving...\n1:M 17 Jan 2026 06:18:42.044 * Background saving started by pid 187\n187:C 17 Jan 2026 06:18:42.056 * DB saved on disk\n187:C 17 Jan 2026 06:18:42.057 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB\n1:M 17 Jan 2026 06:18:42.144 * Background saving terminated with success\n",
  "immich-ml": "\u001b[2;36m[01/17/26 06:13:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting gunicorn \u001b[1;36m23.0\u001b[0m.\u001b[1;36m0\u001b[0m                           \n\u001b[2;36m[01/17/26 06:13:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening at: \u001b[4;94mhttp://\u001b[0m\u001b[1m[\u001b[0m::\u001b[1m]\u001b[0m:\u001b[1;36m3003\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m                \n\u001b[2;36m[01/17/26 06:13:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using worker: immich_ml.config.CustomUvicornWorker \n\u001b[2;36m[01/17/26 06:13:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Booting worker with pid: \u001b[1;36m14\u001b[0m                        \n\u001b[2;36m[01/17/26 06:13:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started server process \u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1m]\u001b[0m                        \n\u001b[2;36m[01/17/26 06:13:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Waiting for application startup.                   \n\u001b[2;36m[01/17/26 06:13:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created in-memory cache with unloading after 300s  \n\u001b[2;36m                    \u001b[0m         of inactivity.                                     \n\u001b[2;36m[01/17/26 06:13:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized request thread pool with \u001b[1;36m4\u001b[0m threads.    \n\u001b[2;36m[01/17/26 06:13:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Application startup complete.                      \n"
}