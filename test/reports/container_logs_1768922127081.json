{
  "dashboard": "2026/01/20 15:13:36 [notice] 1#1: start worker process 24\n10.0.1.187 - - [20/Jan/2026:15:13:36 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:36 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:36 [info] 21#21: *1 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:38 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:38 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:38 [info] 22#22: *3 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:40 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:40 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:40 [info] 23#23: *5 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:42 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:42 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:42 [info] 24#24: *7 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:44 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:44 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:44 [info] 21#21: *9 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:46 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:46 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:46 [info] 21#21: *11 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:48 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:48 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:48 [info] 21#21: *13 client 10.0.1.187 closed keepalive connection\n2026/01/20 15:13:50 [info] 21#21: *15 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:50 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:50 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.1.187 - - [20/Jan/2026:15:13:52 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:52 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:52 [info] 21#21: *17 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:54 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:54 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:54 [info] 21#21: *19 client 10.0.1.187 closed keepalive connection\n2026/01/20 15:13:56 [info] 21#21: *21 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:13:56 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:56 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.1.187 - - [20/Jan/2026:15:13:58 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:13:58 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:13:58 [info] 21#21: *23 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:14:00 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:14:00 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:14:00 [info] 21#21: *25 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:14:02 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:14:02 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:14:02 [info] 21#21: *27 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:15:14:04 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:15:14:04 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 15:14:04 [info] 21#21: *29 client 10.0.1.187 closed keepalive connection\n127.0.0.1 - - [20/Jan/2026:15:14:06 +0000] \"GET / HTTP/1.1\" 200 269330 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:15:14:06 +0000] \"GET / HTTP/1.1\" 200 269330 \"-\" \"Wget\"\n127.0.0.1 - - [20/Jan/2026:15:14:36 +0000] \"GET / HTTP/1.1\" 200 269330 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:15:14:36 +0000] \"GET / HTTP/1.1\" 200 269330 \"-\" \"Wget\"\n",
  "api": "INFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:55555 (Press CTRL+C to quit)\nINFO:     127.0.0.1:46074 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.9:43846 - \"GET /status HTTP/1.0\" 404 Not Found\n[INFO] Watchtower Notification (Plain): Watchtower 1.7.1\nUsing notifications: generic+http\nChecking all containers (except explicitly disabled with label)\nScheduling first run: 2026-01-20 16:13:37 +0000 UTC\nNote that the first check will be performed in 59 minutes, 59 seconds\n\nINFO:     172.18.0.5:60866 - \"POST /watchtower?token=1iYEumNPec3ZmTrof1brrtchVsyURiXH HTTP/1.1\" 200 OK\nINFO:     172.20.0.9:43850 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:43860 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:43866 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:43882 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:60246 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:60254 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:60270 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:60284 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:60292 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:60990 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.9:38666 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:38670 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:38682 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:38686 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:38698 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:40988 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:49362 - \"GET /api/health HTTP/1.1\" 200 OK\n",
  "adguard": "2026/01/20 15:13:08.672422 [info] starting adguard home version=\"AdGuard Home, version v0.107.71\"\n2026/01/20 15:13:08.672949 [info] config_migrator: upgrade yaml from=29 to=30\n2026/01/20 15:13:08.672959 [info] config_migrator: upgrade yaml from=30 to=31\n2026/01/20 15:13:08.672965 [info] config_migrator: upgrade yaml from=31 to=32\n2026/01/20 15:13:08.702801 [info] dhcpd: warning: creating dhcpv4 server err=\"dhcpv4: invalid IP is not an IPv4 address\"\n2026/01/20 15:13:08.707386 [info] tls_manager: using default ciphers\n2026/01/20 15:13:08.707910 [info] tls_manager: parsing multiple pem certificates num=1\n2026/01/20 15:13:08.939352 [info] webapi: initializing\n2026/01/20 15:13:09.010378 [info] warning: private rdns resolution failed; disabling err=\"preparing resolvers: no upstream specified\"\n2026/01/20 15:13:09.010556 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/20 15:13:09.010723 [info] dnsproxy: cache enabled size=4096\n2026/01/20 15:13:09.010745 [info] dnsproxy: max goroutines is set count=300\n2026/01/20 15:13:09.010891 [info] dnsproxy: ratelimit is enabled rps=20 ipv4_subnet_mask_len=24 ipv6_subnet_mask_len=56\n2026/01/20 15:13:09.010958 [info] dnsproxy: server will refuse requests of type any\n2026/01/20 15:13:09.011192 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/20 15:13:09.011267 [info] dnsproxy: cache enabled size=4194304\n2026/01/20 15:13:09.011303 [info] dnsproxy: max goroutines is set count=300\n2026/01/20 15:13:09.012856 [info] addrproc: processing addresses\n2026/01/20 15:13:09.014012 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work\n2026/01/20 15:13:09.014069 [info] permcheck: changed permissions type=file path=/opt/adguardhome/conf/AdGuardHome.yaml\n2026/01/20 15:13:09.014142 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data\n2026/01/20 15:13:09.014194 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data/filters\n2026/01/20 15:13:09.014287 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/sessions.db\n2026/01/20 15:13:09.014379 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/stats.db\n2026/01/20 15:13:09.014497 [info] webapi: AdGuard Home is available at the following addresses:\n2026/01/20 15:13:09.014909 [info] go to http://127.0.0.1:8083\n2026/01/20 15:13:09.014920 [info] go to http://[::1]:8083\n2026/01/20 15:13:09.014924 [info] go to http://172.20.0.5:8083\n2026/01/20 15:13:09.015410 [info] starting plain server server=plain addr=0.0.0.0:8083\n2026/01/20 15:13:09.015718 [info] go to https://10.0.1.187:443\n2026/01/20 15:13:09.015738 [info] starting https server server=https\n2026/01/20 15:13:09.028928 [info] dnsproxy: starting dns proxy server\n2026/01/20 15:13:09.029715 [info] dnsproxy: creating udp server socket addr=0.0.0.0:53\n2026/01/20 15:13:09.029926 [info] dnsproxy: listening to udp addr=[::]:53\n2026/01/20 15:13:09.030036 [info] dnsproxy: creating tcp server socket addr=0.0.0.0:53\n2026/01/20 15:13:09.030178 [info] dnsproxy: listening to tcp addr=[::]:53\n2026/01/20 15:13:09.030314 [info] dnsproxy: creating tls server socket addr=0.0.0.0:853\n2026/01/20 15:13:09.030501 [info] dnsproxy: listening to tls addr=[::]:853\n2026/01/20 15:13:09.031235 [info] dnsproxy: creating quic listener addr=0.0.0.0:853\n2026/01/20 15:13:09.031519 failed to sufficiently increase receive buffer size (was: 1024 kiB, wanted: 7168 kiB, got: 2048 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n2026/01/20 15:13:09.031813 [info] dnsproxy: listening quic addr=[::]:853\n2026/01/20 15:13:09.032349 [info] dnsproxy: entering udp listener loop addr=[::]:53\n2026/01/20 15:13:09.033144 [info] dnsproxy: entering dns-over-quic listener loop addr=[::]:853\n2026/01/20 15:13:09.033175 [info] dnsproxy: entering listener loop proto=tcp addr=[::]:53\n2026/01/20 15:13:09.033204 [info] dnsproxy: entering listener loop proto=tls addr=[::]:853\n2026/01/20 15:13:38.526512 [info] filtering: saving contents id=1 path=/opt/adguardhome/work/data/filters/1.txt\n2026/01/20 15:13:38.594831 [info] filtering: filter updated id=1 bytes_written=40434673 rules_count=2000969\n2026/01/20 15:13:38.594854 [info] filtering: updated filter id=1 rules_count=2000969 prev_rules_count=0\n",
  "invidious": "[production] Invidious is ready to lead at http://0.0.0.0:3000\n2026-01-20 15:13:20 UTC [info] jobs: running ClearExpiredItems job\n2026-01-20 15:13:21 UTC [info] jobs: ClearExpiredItems done.\n2026-01-20 15:13:21 UTC [info] InstanceListRefreshJob: Done, sleeping for 30 minutes\n2026-01-20 15:13:49 UTC [info] 200 GET /api/v1/stats 2.28ms\n2026-01-20 15:14:19 UTC [info] 200 GET /api/v1/stats 71.08Âµs\n2026-01-20 15:14:49 UTC [info] 200 GET /api/v1/stats 84.1Âµs\n",
  "breezewiki": "note: config file not detected, using defaults\nnote: 1 items loaded from environment variables\nYour Web application is running at http://localhost:10416.\nStop this program at any time to terminate the Web Server.\n",
  "redlib": " ERROR redlib::client > Got an invalid response from reddit expected value at line 1 column 1. Status code: 403 Forbidden\nRate limit check failed: Failed to parse page JSON data: expected value at line 1 column 1 | /r/reddit/hot.json?&raw_json=1\nThis may cause issues with the rate limit.\nPlease report this error with the above information.\nhttps://github.com/redlib-org/redlib/issues/new?assignees=sigaloid&labels=bug&title=%F0%9F%90%9B+Bug+Report%3A+Rate+limit+mismatch\nStarting Redlib...\nRunning Redlib v0.36.0 on [::]:8081!\n",
  "scribe": "{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T15:14:14Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"9ac58219-cee5-4eca-a6d4-1793ce662fa8\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T15:14:14Z\",\"local\":{\"status\":200,\"duration\":\"45.76ms\",\"request_id\":\"9ac58219-cee5-4eca-a6d4-1793ce662fa8\"}}\n",
  "anonymousoverflow": "",
  "searxng": "SearXNG 2026.1.20-410996df9\nUpdating certificates in /etc/ssl/certs...\n0 added, 0 removed; done.\nRunning hooks in /etc/ca-certificates/update.d...\ndone.\n[INFO] Starting granian (main PID: 1)\n[INFO] Listening at: http://:::8080\n[INFO] Spawning worker-1 with PID: 922\n2026-01-20 15:13:35,148 ERROR:searx.engines: loading engine ahmia failed: set engine to inactive!\n2026-01-20 15:13:35,374 ERROR:searx.engines: loading engine torch failed: set engine to inactive!\n2026-01-20 15:13:35,514 WARNING:searx.botdetection.config: missing config file: /etc/searxng/limiter.toml\n[INFO] Started worker-1\n",
  "rimgo": "\n â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” \n â”‚                  Fiber v2.52.10                   â”‚ \n â”‚               http://127.0.0.1:3002               â”‚ \n â”‚       (bound on host 0.0.0.0 and port 3002)       â”‚ \n â”‚                                                   â”‚ \n â”‚ Handlers ............ 57  Processes ........... 1 â”‚ \n â”‚ Prefork ....... Disabled  PID ................. 1 â”‚ \n â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ \n\n",
  "cobalt": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/20 15:13:15 [notice] 1#1: using the \"epoll\" event method\n2026/01/20 15:13:15 [notice] 1#1: nginx/1.29.4\n2026/01/20 15:13:15 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/20 15:13:15 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/20 15:13:15 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/20 15:13:15 [notice] 1#1: start worker processes\n2026/01/20 15:13:15 [notice] 1#1: start worker process 30\n2026/01/20 15:13:15 [notice] 1#1: start worker process 31\n2026/01/20 15:13:15 [notice] 1#1: start worker process 32\n2026/01/20 15:13:15 [notice] 1#1: start worker process 33\n",
  "memos": "2026/01/20 15:13:08 WARN failed to find migration history in pre-migrate error=\"SQL logic error: no such table: migration_history (1)\"\n---\nServer profile\nversion: 0.24.0\ndata: /var/opt/memos\ndsn: /var/opt/memos/memos_prod.db\naddr: \nport: 5230\nmode: prod\ndriver: sqlite\n---\nVersion 0.24.0 has been started on port 5230\n---\nSee more in:\nðŸ‘‰Website: https://usememos.com\nðŸ‘‰GitHub: https://github.com/usememos/memos\n---\n\nâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•\nâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘\nâ–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘\nâ•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•\n",
  "portainer": "\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[31mWRN\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cli/cli.go:168\u001b[0m\u001b[36m >\u001b[0m the --no-analytics flag has been kept to allow migration of instances running a previous version of Portainer with this flag enabled, to version 2.0 where enabling this flag will have no effect |\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:325\u001b[0m\u001b[36m >\u001b[0m encryption key file not present | \u001b[36mfilename=\u001b[0m/run/secrets/portainer\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:365\u001b[0m\u001b[36m >\u001b[0m proceeding without encryption key |\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/database/boltdb/db.go:137\u001b[0m\u001b[36m >\u001b[0m loading PortainerDB | \u001b[36mfilename=\u001b[0mportainer.db\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/internal/ssl/ssl.go:79\u001b[0m\u001b[36m >\u001b[0m no cert files found, generating self signed SSL certificates |\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:507\u001b[0m\u001b[36m >\u001b[0m created admin user with the given password. |\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/chisel/service.go:228\u001b[0m\u001b[36m >\u001b[0m generated a new Chisel private key file | \u001b[36mprivate-key=\u001b[0m/data/chisel/private-key.pem\n2026/01/20 15:13:10 server: Reverse tunnelling enabled\n2026/01/20 15:13:10 server: Fingerprint H9es+vRXQXa8E+oDyz4mrjCxlxcnffs1pgRbEUT8stQ=\n2026/01/20 15:13:10 server: Listening on http://0.0.0.0:8000\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:636\u001b[0m\u001b[36m >\u001b[0m starting Portainer | \u001b[36mbuild_number=\u001b[0m251 \u001b[36mgo_version=\u001b[0m1.24.11 \u001b[36mimage_tag=\u001b[0m2.33.6-linux-amd64 \u001b[36mnodejs_version=\u001b[0m18.20.8 \u001b[36mversion=\u001b[0m2.33.6 \u001b[36mwebpack_version=\u001b[0m5.88.2 \u001b[36myarn_version=\u001b[0m1.22.22\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:367\u001b[0m\u001b[36m >\u001b[0m starting HTTPS server | \u001b[36mbind_address=\u001b[0m:9443\n\u001b[90m2026/01/20 03:13PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:351\u001b[0m\u001b[36m >\u001b[0m starting HTTP server | \u001b[36mbind_address=\u001b[0m:9000\n",
  "wg-easy": "2026-01-20T15:13:08.529Z Server Listening on http://0.0.0.0:51821\n$ wg genkey\n2026-01-20T15:13:08.545Z WireGuard Loading configuration...\n$ echo ***hidden*** | wg pubkey\n2026-01-20T15:13:08.660Z WireGuard Configuration generated.\n2026-01-20T15:13:08.661Z WireGuard Config saving...\n2026-01-20T15:13:08.663Z WireGuard Config saved.\n$ wg-quick down wg0\n$ wg-quick up wg0\n2026-01-20T15:13:09.288Z WireGuard Config syncing...\n$ wg syncconf wg0 <(wg-quick strip wg0)\n2026-01-20T15:13:09.348Z WireGuard Config synced.\n",
  "odido-booster": "INFO:odido.service:Service initialized\n/app/app/main.py:43: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"startup\")\n/app/app/main.py:48: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"shutdown\")\nINFO:odido.service:Odido API not configured - skipping remaining data sync\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nINFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8085 (Press CTRL+C to quit)\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:All renewal attempts failed - check Odido API credentials and network connectivity\nINFO:     127.0.0.1:40592 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51770 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:34626 - \"GET /docs HTTP/1.1\" 200 OK\n",
  "vert": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: /etc/nginx/conf.d/default.conf differs from the packaged version\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/20 15:13:13 [notice] 1#1: using the \"epoll\" event method\n2026/01/20 15:13:13 [notice] 1#1: nginx/1.28.1\n2026/01/20 15:13:13 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/20 15:13:13 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/20 15:13:13 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/20 15:13:13 [notice] 1#1: start worker processes\n2026/01/20 15:13:13 [notice] 1#1: start worker process 29\n2026/01/20 15:13:13 [notice] 1#1: start worker process 30\n2026/01/20 15:13:13 [notice] 1#1: start worker process 31\n2026/01/20 15:13:13 [notice] 1#1: start worker process 32\n127.0.0.1 - - [20/Jan/2026:15:13:18 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:15:13:48 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:15:14:18 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:15:14:48 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n",
  "immich": "\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:13:59 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m120000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:13:59 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m130000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:03 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m140000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:03 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m150000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:03 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m160000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:03 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m170000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:03 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m180000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:06 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m190000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:06 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m200000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:06 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m210000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:07 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32mSuccessfully imported 219997 geodata records in 20.82s (10565 records/second)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32mGeodata import completed\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MetadataService]\u001b[39m \u001b[32mInitialized local reverse geocoder\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mPlugin immich-core is up to date (version 2.0.0). Skipping\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully processed core plugin: immich-core (version 2.0.0)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully loaded plugin: immich-core\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:ServerService]\u001b[39m \u001b[32mFeature Flags: {\n  \"smartSearch\": true,\n  \"facialRecognition\": true,\n  \"duplicateDetection\": true,\n  \"map\": true,\n  \"reverseGeocoding\": true,\n  \"importFaces\": false,\n  \"sidecar\": true,\n  \"search\": true,\n  \"trash\": true,\n  \"oauth\": false,\n  \"oauthAutoLaunch\": false,\n  \"ocr\": true,\n  \"passwordLogin\": true,\n  \"configFile\": false,\n  \"email\": false\n}\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:SystemConfigService]\u001b[39m \u001b[32mLogLevel=log (set via system config)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MachineLearningRepository]\u001b[39m \u001b[32mMachine learning server became healthy (http://127.0.0.1:3003).\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestFactory]\u001b[39m \u001b[32mStarting Nest application...\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsCommonModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyCoreModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mDiscoveryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryCoreModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsRootModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mMicroservicesModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestApplication]\u001b[39m \u001b[32mNest application successfully started\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 3:14:18 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:Bootstrap]\u001b[39m \u001b[32mImmich Microservices is running [v2.4.1] [production] \u001b[39m\n",
  "wikiless": "Wikiless 10.0.1.187:8180 running on http://0.0.0.0:8180\nCleared cached static media files. You can turn this off by setting the config.cache_control to false.\nFetched https://en.wikipedia.org/?useskin=vector from Wikipedia.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\n",
  "unbound": "[1768921987] unbound[1:0] warning: so-sndbuf 4194304 was not granted. Got 425984. To fix: start with root permissions(linux) or sysctl bigger net.core.wmem_max(linux) or kern.ipc.maxsockbuf(bsd) values. or set so-sndbuf: 0 (use system value).\n",
  "gluetun": "|   â”œâ”€â”€ Log: no\n|   â”œâ”€â”€ Read header timeout: 1s\n|   â””â”€â”€ Read timeout: 3s\nâ”œâ”€â”€ Control server settings:\n|   â”œâ”€â”€ Listening address: :8000\n|   â”œâ”€â”€ Logging: yes\n|   â””â”€â”€ Authentication file path: /gluetun/auth/config.toml\nâ”œâ”€â”€ Storage settings:\n|   â””â”€â”€ Filepath: /gluetun/servers.json\nâ”œâ”€â”€ OS Alpine settings:\n|   â”œâ”€â”€ Process UID: 1000\n|   â””â”€â”€ Process GID: 1000\nâ”œâ”€â”€ Public IP settings:\n|   â”œâ”€â”€ IP file path: /tmp/gluetun/ip\n|   â”œâ”€â”€ Public IP data base API: ipinfo\n|   â””â”€â”€ Public IP data backup APIs:\n|       â”œâ”€â”€ ifconfigco\n|       â”œâ”€â”€ ip2location\n|       â””â”€â”€ cloudflare\nâ””â”€â”€ Version settings:\n    â””â”€â”€ Enabled: yes\n2026-01-20T15:13:09Z INFO [routing] default route found: interface eth0, gateway 172.20.0.1, assigned IP 172.20.0.254 and family v4\n2026-01-20T15:13:09Z INFO [routing] adding route for 0.0.0.0/0\n2026-01-20T15:13:09Z INFO [firewall] setting allowed subnets...\n2026-01-20T15:13:09Z INFO [routing] default route found: interface eth0, gateway 172.20.0.1, assigned IP 172.20.0.254 and family v4\n2026-01-20T15:13:09Z INFO [routing] adding route for 172.20.0.0/16\n2026-01-20T15:13:09Z INFO [dns] using plaintext DNS at address 9.9.9.9\n2026-01-20T15:13:09Z INFO [healthcheck] listening on 127.0.0.1:9999\n2026-01-20T15:13:09Z INFO [http proxy] listening on :8888\n2026-01-20T15:13:09Z INFO [http server] http server listening on [::]:8000\n2026-01-20T15:13:09Z INFO [firewall] allowing VPN connection...\n2026-01-20T15:13:09Z INFO [wireguard] Using available kernelspace implementation\n2026-01-20T15:13:09Z INFO [wireguard] Connecting to 80.79.7.101:51820\n2026-01-20T15:13:09Z INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 10416 through interface tun0...\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 8080 through interface tun0...\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 8081 through interface tun0...\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 8085 through interface tun0...\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 8180 through interface tun0...\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 3000 through interface tun0...\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 3002 through interface tun0...\n2026-01-20T15:13:09Z INFO [firewall] setting allowed input port 8280 through interface tun0...\n2026-01-20T15:13:10Z INFO [firewall] setting allowed input port 8480 through interface tun0...\n2026-01-20T15:13:10Z INFO [firewall] setting allowed input port 80 through interface tun0...\n2026-01-20T15:13:10Z INFO [firewall] setting allowed input port 24153 through interface tun0...\n2026-01-20T15:13:10Z INFO [firewall] setting allowed input port 8282 through interface tun0...\n2026-01-20T15:13:10Z INFO [firewall] setting allowed input port 9000 through interface tun0...\n2026-01-20T15:13:10Z INFO [firewall] setting allowed input port 2283 through interface tun0...\n2026-01-20T15:13:10Z INFO [ip getter] Public IP address is 80.79.7.119 (Netherlands, South Holland, Naaldwijk - source: ipinfo+ifconfig.co+ip2location+cloudflare)\n2026-01-20T15:13:10Z INFO [vpn] You are running on the bleeding edge of latest!\n",
  "companion": "    at KB (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:6633:34266) undefined\n[INFO] No local config file found, using default config\nLoaded Configuration {\n  server: {\n    port: 8282,\n    host: \"0.0.0.0\",\n    use_unix_socket: false,\n    unix_socket_path: \"/tmp/invidious-companion.sock\",\n    base_path: \"/companion\",\n    secret_key: \"vRsHsShboPK4h5R5\",\n    verify_requests: false,\n    encrypt_query_params: false,\n    enable_metrics: false\n  },\n  cache: { enabled: true, directory: \"/var/tmp\" },\n  networking: {\n    proxy: null,\n    ipv6_block: null,\n    fetch: {\n      timeout_ms: 30000,\n      retry: {\n        enabled: false,\n        times: 1,\n        initial_debounce: 0,\n        debounce_multiplier: 0\n      }\n    },\n    videoplayback: { ump: false, video_fetch_chunk_size_mb: 5 }\n  },\n  jobs: {\n    youtube_session: { po_token_enabled: true, frequency: \"*/5 * * * *\" }\n  },\n  youtube_session: { oauth_enabled: false, cookies: \"\" }\n}\n[INFO] Using Invidious companion version 2026.01.13-cd52e7f\n[INFO] job po_token is active.\n[INFO] Starting PO token generation in background...\n[INFO] Server successfully started at http://0.0.0.0:8282/companion\n[INFO] the \"Not implemented: HTMLCanvasElement.prototype.getContext\" error is normal. Please do not open a bug report about it.\nError: Not implemented: HTMLCanvasElement.prototype.getContext (without installing the canvas npm package)\n    at module.exports (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/browser/not-implemented.js:9:17)\n    at HTMLCanvasElementImpl.getContext (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/living/nodes/HTMLCanvasElement-impl.js:42:5)\n    at HTMLCanvasElement.getContext (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/living/generated/HTMLCanvasElement.js:131:58)\n    at eval (eval at <anonymous> (eval at <anonymous> (eval at <anonymous> (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9))))), <anonymous>:1:142)\n    at nB (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:229:36528)\n    at K.eval [as C] (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:229:55019)\n    at UC (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:229:23567)\n    at Lv (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:229:3412)\n    at n (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:229:2041)\n    at KB (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:229:34266) undefined\n",
  "vertd": "[2026-01-20T15:13:08Z INFO  vertd] starting vertd\n[2026-01-20T15:13:10Z INFO  vertd] working w/ ffmpeg 6.1.1-3ubuntu5 and ffprobe 6.1.1-3ubuntu5\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] *******\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] you're running vertd on a docker container, but no GPU was detected.\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] this usually is because you're running Docker under WSL or because\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] you are not passing the GPU device correctly.\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] \n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] if this doesn't seem right, make sure to provide the following info when\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] asking for help:\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] - adapter name: llvmpipe (LLVM 20.1.2, 256 bits)\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] - adapter vendor: 0x10005\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] - backend: vulkan\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] - device ID: 0\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] - device type: Cpu\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] - driver: llvmpipe\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] - driver info: Mesa 25.0.7-0ubuntu0.24.04.2 (LLVM 20.1.2)\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] \n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] vertd will fall back to CPU rendering to ensure conversions can still proceed.\n[2026-01-20T15:13:12Z WARN  vertd::converter::gpu] *******\n[2026-01-20T15:13:12Z INFO  vertd] using CPU rendering (software encoding) -- this will be slower than GPU acceleration\n[2026-01-20T15:13:12Z INFO  vertd::http] http server listening on 0.0.0.0:24153\n",
  "watchtower": "time=\"2026-01-20T15:13:37Z\" level=info msg=\"Watchtower 1.7.1\"\ntime=\"2026-01-20T15:13:37Z\" level=info msg=\"Using notifications: generic+http\"\ntime=\"2026-01-20T15:13:37Z\" level=info msg=\"Checking all containers (except explicitly disabled with label)\"\ntime=\"2026-01-20T15:13:37Z\" level=info msg=\"Scheduling first run: 2026-01-20 16:13:37 +0000 UTC\"\ntime=\"2026-01-20T15:13:37Z\" level=info msg=\"Note that the first check will be performed in 59 minutes, 59 seconds\"\n",
  "invidious-db": "2026-01-20 15:13:12.184 UTC [49] LOG:  database system was shut down at 2026-01-20 15:13:10 UTC\n2026-01-20 15:13:12.193 UTC [48] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init-invidious-db.sh\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE TYPE\nCREATE TABLE\nGRANT\nCREATE TABLE\nGRANT\n\n2026-01-20 15:13:13.220 UTC [48] LOG:  received fast shutdown request\nwaiting for server to shut down....2026-01-20 15:13:13.221 UTC [48] LOG:  aborting any active transactions\n2026-01-20 15:13:13.223 UTC [48] LOG:  background worker \"logical replication launcher\" (PID 55) exited with exit code 1\n2026-01-20 15:13:13.224 UTC [50] LOG:  shutting down\n2026-01-20 15:13:13.259 UTC [48] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-20 15:13:13.343 UTC [1] LOG:  starting PostgreSQL 14.20 (Debian 14.20-1.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n2026-01-20 15:13:13.343 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-20 15:13:13.343 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-20 15:13:13.347 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-20 15:13:13.353 UTC [82] LOG:  database system was shut down at 2026-01-20 15:13:13 UTC\n2026-01-20 15:13:13.366 UTC [1] LOG:  database system is ready to accept connections\n",
  "wikiless-redis": "1:C 20 Jan 2026 15:13:14.351 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 20 Jan 2026 15:13:14.352 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 20 Jan 2026 15:13:14.352 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 20 Jan 2026 15:13:14.352 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 20 Jan 2026 15:13:14.353 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 20 Jan 2026 15:13:14.353 * monotonic clock: POSIX clock_gettime\n1:M 20 Jan 2026 15:13:14.355 * Running mode=standalone, port=6379.\n1:M 20 Jan 2026 15:13:14.356 * Server initialized\n1:M 20 Jan 2026 15:13:14.356 * Ready to accept connections tcp\n",
  "searxng-redis": "1:C 20 Jan 2026 15:13:07.555 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 20 Jan 2026 15:13:07.556 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 20 Jan 2026 15:13:07.556 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 20 Jan 2026 15:13:07.556 * Configuration loaded\n1:M 20 Jan 2026 15:13:07.556 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 20 Jan 2026 15:13:07.556 * monotonic clock: POSIX clock_gettime\n1:M 20 Jan 2026 15:13:07.557 * Running mode=standalone, port=6379.\n1:M 20 Jan 2026 15:13:07.558 * Server initialized\n1:M 20 Jan 2026 15:13:07.558 * Ready to accept connections tcp\n",
  "immich-db": "selecting default shared_buffers ... 128MB\nselecting default time zone ... Etc/UTC\ncreating configuration files ... ok\nrunning bootstrap script ... ok\nperforming post-bootstrap initialization ... ok\ninitdb: warning: enabling \"trust\" authentication for local connections\nYou can change this by editing pg_hba.conf or using the option -A, or\n--auth-local and --auth-host, the next time you run initdb.\nsyncing data to disk ... ok\n\n\nSuccess. You can now start the database server using:\n\n    pg_ctl -D /var/lib/postgresql/data -l logfile start\n\n2026-01-20 15:13:12.122 GMT [48] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 15:13:12.122 GMT [48] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\nwaiting for server to start....2026-01-20 15:13:12.157 GMT [53] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 15:13:12.158 GMT [53] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 15:13:12.190 UTC [53] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-20 15:13:12.194 UTC [53] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-20 15:13:12.203 UTC [54] LOG:  database system was shut down at 2026-01-20 15:13:10 UTC\n2026-01-20 15:13:12.210 UTC [53] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*\n\n2026-01-20 15:13:12.728 UTC [53] LOG:  received fast shutdown request\nwaiting for server to shut down....2026-01-20 15:13:12.730 UTC [53] LOG:  aborting any active transactions\n2026-01-20 15:13:12.735 UTC [53] LOG:  background worker \"logical replication launcher\" (PID 63) exited with exit code 1\n2026-01-20 15:13:12.736 UTC [58] LOG:  shutting down\n2026-01-20 15:13:12.871 UTC [53] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-20 15:13:12.948 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 15:13:12.949 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 15:13:12.987 UTC [1] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-20 15:13:12.987 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-20 15:13:12.987 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-20 15:13:12.990 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-20 15:13:12.995 UTC [71] LOG:  database system was shut down at 2026-01-20 15:13:12 UTC\n2026-01-20 15:13:13.006 UTC [1] LOG:  database system is ready to accept connections\n2026-01-20 15:13:38.768 UTC [105] ERROR:  relation \"system_metadata\" does not exist at character 21\n2026-01-20 15:13:38.768 UTC [105] STATEMENT:  select \"value\" from \"system_metadata\" where \"key\" = $1\n",
  "immich-redis": "1:M 20 Jan 2026 15:13:08.685 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:M 20 Jan 2026 15:13:08.686 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo\n1:M 20 Jan 2026 15:13:08.686 * Valkey version=9.0.1, bits=64, commit=00000000, modified=0, pid=1, just started\n1:M 20 Jan 2026 15:13:08.686 # Warning: no config file specified, using the default config. In order to specify a config file use valkey-server /path/to/valkey.conf\n1:M 20 Jan 2026 15:13:08.688 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 20 Jan 2026 15:13:08.688 * monotonic clock: POSIX clock_gettime\n1:M 20 Jan 2026 15:13:08.702 * Running mode=standalone, port=6379.\n1:M 20 Jan 2026 15:13:08.705 * Server initialized\n1:M 20 Jan 2026 15:13:08.705 * Ready to accept connections tcp\n",
  "immich-ml": "\u001b[2;36m[01/20/26 15:13:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting gunicorn \u001b[1;36m23.0\u001b[0m.\u001b[1;36m0\u001b[0m                           \n\u001b[2;36m[01/20/26 15:13:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening at: \u001b[4;94mhttp://\u001b[0m\u001b[1m[\u001b[0m::\u001b[1m]\u001b[0m:\u001b[1;36m3003\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m                \n\u001b[2;36m[01/20/26 15:13:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using worker: immich_ml.config.CustomUvicornWorker \n\u001b[2;36m[01/20/26 15:13:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Booting worker with pid: \u001b[1;36m14\u001b[0m                        \n\u001b[2;36m[01/20/26 15:13:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started server process \u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1m]\u001b[0m                        \n\u001b[2;36m[01/20/26 15:13:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Waiting for application startup.                   \n\u001b[2;36m[01/20/26 15:13:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created in-memory cache with unloading after 300s  \n\u001b[2;36m                    \u001b[0m         of inactivity.                                     \n\u001b[2;36m[01/20/26 15:13:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized request thread pool with \u001b[1;36m4\u001b[0m threads.    \n\u001b[2;36m[01/20/26 15:13:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Application startup complete.                      \n"
}