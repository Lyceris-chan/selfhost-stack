{
  "dashboard": "10.0.0.72 - - [17/Jan/2026:06:33:08 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:08 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.0.72 - - [17/Jan/2026:06:33:10 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:10 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:10 [info] 20#20: *4 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:12 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:12 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:12 [info] 22#22: *6 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:14 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:14 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:14 [info] 21#21: *8 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:16 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:16 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:16 [info] 21#21: *10 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:18 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:18 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:18 [info] 21#21: *12 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:20 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:20 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:20 [info] 21#21: *14 client 10.0.0.72 closed keepalive connection\n2026/01/17 06:33:22 [info] 21#21: *16 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:22 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:22 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.0.72 - - [17/Jan/2026:06:33:24 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:24 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:24 [info] 21#21: *18 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:26 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:26 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:26 [info] 21#21: *20 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:28 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:28 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:28 [info] 21#21: *22 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:30 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:30 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:30 [info] 21#21: *24 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:32 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:32 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:32 [info] 21#21: *26 client 10.0.0.72 closed keepalive connection\n127.0.0.1 - - [17/Jan/2026:06:33:33 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:33:33 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n10.0.0.72 - - [17/Jan/2026:06:33:34 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:34 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:34 [info] 21#21: *29 client 10.0.0.72 closed keepalive connection\n10.0.0.72 - - [17/Jan/2026:06:33:36 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.0.72 - - [17/Jan/2026:06:33:36 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/17 06:33:36 [info] 21#21: *31 client 10.0.0.72 closed keepalive connection\n127.0.0.1 - - [17/Jan/2026:06:34:03 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:34:03 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n127.0.0.1 - - [17/Jan/2026:06:34:33 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:34:33 +0000] \"GET / HTTP/1.1\" 200 267543 \"-\" \"Wget\"\n",
  "api": "INFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:55555 (Press CTRL+C to quit)\nINFO:     127.0.0.1:57560 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:58888 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:37774 - \"GET /api/health HTTP/1.1\" 200 OK\n[INFO] Watchtower Notification (Plain): Watchtower 1.7.1\nUsing notifications: generic+http\nChecking all containers (except explicitly disabled with label)\nScheduling first run: 2026-01-17 07:32:33 +0000 UTC\nNote that the first check will be performed in 59 minutes, 59 seconds\n\nINFO:     172.18.0.4:43306 - \"POST /watchtower?token=EQ3WPaGh0jLv6aBWydUTQtWwrP6iLQWk HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51454 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.8:50506 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:55874 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.8:50516 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:50528 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:50538 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:35658 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:35662 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:35670 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:35682 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:35698 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:44158 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:44170 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:57042 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.8:44174 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:44186 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:44200 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.8:50726 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:41296 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:57630 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:39086 - \"GET /api/health HTTP/1.1\" 200 OK\n",
  "adguard": "2026/01/17 06:31:21.734321 [info] starting adguard home version=\"AdGuard Home, version v0.107.71\"\n2026/01/17 06:31:21.734886 [info] config_migrator: upgrade yaml from=29 to=30\n2026/01/17 06:31:21.734901 [info] config_migrator: upgrade yaml from=30 to=31\n2026/01/17 06:31:21.734908 [info] config_migrator: upgrade yaml from=31 to=32\n2026/01/17 06:31:21.783229 [info] dhcpd: warning: creating dhcpv4 server err=\"dhcpv4: invalid IP is not an IPv4 address\"\n2026/01/17 06:31:21.787642 [info] tls_manager: using default ciphers\n2026/01/17 06:31:21.787774 [info] tls_manager: parsing multiple pem certificates num=1\n2026/01/17 06:31:21.849467 [info] webapi: initializing\n2026/01/17 06:31:21.857738 [info] warning: private rdns resolution failed; disabling err=\"preparing resolvers: no upstream specified\"\n2026/01/17 06:31:21.857889 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/17 06:31:21.857966 [info] dnsproxy: cache enabled size=4096\n2026/01/17 06:31:21.858032 [info] dnsproxy: max goroutines is set count=300\n2026/01/17 06:31:21.858185 [info] dnsproxy: ratelimit is enabled rps=20 ipv4_subnet_mask_len=24 ipv6_subnet_mask_len=56\n2026/01/17 06:31:21.858248 [info] dnsproxy: server will refuse requests of type any\n2026/01/17 06:31:21.858319 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/17 06:31:21.858374 [info] dnsproxy: cache enabled size=4194304\n2026/01/17 06:31:21.858446 [info] dnsproxy: max goroutines is set count=300\n2026/01/17 06:31:21.858998 [info] addrproc: processing addresses\n2026/01/17 06:31:21.859786 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work\n2026/01/17 06:31:21.859825 [info] permcheck: changed permissions type=file path=/opt/adguardhome/conf/AdGuardHome.yaml\n2026/01/17 06:31:21.859848 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data\n2026/01/17 06:31:21.859940 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data/filters\n2026/01/17 06:31:21.859966 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/sessions.db\n2026/01/17 06:31:21.860013 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/stats.db\n2026/01/17 06:31:21.860067 [info] webapi: AdGuard Home is available at the following addresses:\n2026/01/17 06:31:21.860316 [info] go to http://127.0.0.1:8083\n2026/01/17 06:31:21.860331 [info] go to http://[::1]:8083\n2026/01/17 06:31:21.860335 [info] go to http://172.20.0.2:8083\n2026/01/17 06:31:21.860524 [info] starting plain server server=plain addr=0.0.0.0:8083\n2026/01/17 06:31:21.860756 [info] go to https://10.0.0.72:443\n2026/01/17 06:31:21.860771 [info] starting https server server=https\n2026/01/17 06:31:21.863959 [info] dnsproxy: starting dns proxy server\n2026/01/17 06:31:21.863979 [info] dnsproxy: creating udp server socket addr=0.0.0.0:53\n2026/01/17 06:31:21.864051 [info] dnsproxy: listening to udp addr=[::]:53\n2026/01/17 06:31:21.864091 [info] dnsproxy: creating tcp server socket addr=0.0.0.0:53\n2026/01/17 06:31:21.864189 [info] dnsproxy: listening to tcp addr=[::]:53\n2026/01/17 06:31:21.864205 [info] dnsproxy: creating tls server socket addr=0.0.0.0:853\n2026/01/17 06:31:21.864244 [info] dnsproxy: listening to tls addr=[::]:853\n2026/01/17 06:31:21.864254 [info] dnsproxy: creating quic listener addr=0.0.0.0:853\n2026/01/17 06:31:21.864346 failed to sufficiently increase receive buffer size (was: 1024 kiB, wanted: 7168 kiB, got: 2048 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n2026/01/17 06:31:21.864519 [info] dnsproxy: listening quic addr=[::]:853\n2026/01/17 06:31:21.864685 [info] dnsproxy: entering listener loop proto=tcp addr=[::]:53\n2026/01/17 06:31:21.864732 [info] dnsproxy: entering udp listener loop addr=[::]:53\n2026/01/17 06:31:21.864810 [info] dnsproxy: entering listener loop proto=tls addr=[::]:853\n2026/01/17 06:31:21.864821 [info] dnsproxy: entering dns-over-quic listener loop addr=[::]:853\n2026/01/17 06:31:26.967368 [error] filtering: changing last modified time err=\"chtimes /opt/adguardhome/work/data/filters/1.txt: no such file or directory\"\n2026/01/17 06:31:26.967398 [error] filtering: updating filter url=https://raw.githubusercontent.com/Lyceris-chan/dns-blocklist-generator/main/blocklist.txt err=\"reading from url: Get \\\"https://raw.githubusercontent.com/Lyceris-chan/dns-blocklist-generator/main/blocklist.txt\\\": dial tcp [2606:50c0:8000::154]:443: connect: network is unreachable\\ndial tcp [2606:50c0:8001::154]:443: connect: network is unreachable\\ndial tcp [2606:50c0:8002::154]:443: connect: network is unreachable\\ndial tcp [2606:50c0:8003::154]:443: connect: network is unreachable\"\n",
  "invidious": "[production] Invidious is ready to lead at http://0.0.0.0:3000\n2026-01-17 06:32:42 UTC [info] jobs: running ClearExpiredItems job\n2026-01-17 06:32:42 UTC [info] jobs: ClearExpiredItems done.\n2026-01-17 06:32:44 UTC [info] InstanceListRefreshJob: failed to parse information from 'yewtu.be' because \"Expected Hash for #[](key : String), not Nil\"\n\"/usr/share/crystal/src/json/any.cr:113:7 in 'begin'\nsrc/invidious/jobs.cr:37:15 in '->'\n/usr/share/crystal/src/fiber.cr:170:11 in 'run'\n???\"  \n2026-01-17 06:32:44 UTC [info] InstanceListRefreshJob: Done, sleeping for 30 minutes\n2026-01-17 06:33:12 UTC [info] 200 GET /api/v1/stats 17.18ms\n2026-01-17 06:33:42 UTC [info] 200 GET /api/v1/stats 63.3Âµs\n2026-01-17 06:34:12 UTC [info] 200 GET /api/v1/stats 70.08Âµs\n2026-01-17 06:34:42 UTC [info] 200 GET /api/v1/stats 77.02Âµs\n",
  "breezewiki": "note: config file not detected, using defaults\nnote: 1 items loaded from environment variables\nYour Web application is running at http://localhost:10416.\nStop this program at any time to terminate the Web Server.\n",
  "redlib": " ERROR redlib::client > Got an invalid response from reddit expected value at line 1 column 1. Status code: 403 Forbidden\nRate limit check failed: Failed to parse page JSON data: expected value at line 1 column 1 | /r/reddit/hot.json?&raw_json=1\nThis may cause issues with the rate limit.\nPlease report this error with the above information.\nhttps://github.com/redlib-org/redlib/issues/new?assignees=sigaloid&labels=bug&title=%F0%9F%90%9B+Bug+Report%3A+Rate+limit+mismatch\nStarting Redlib...\nRunning Redlib v0.36.0 on [::]:8081!\n",
  "scribe": "{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:33:32Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"9bcc8b35-f622-440c-9175-4394807e4fa0\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:33:32Z\",\"local\":{\"status\":200,\"duration\":\"19.36ms\",\"request_id\":\"9bcc8b35-f622-440c-9175-4394807e4fa0\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:34:32Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"e0423d39-8486-4e82-8e02-dae4cd2e1ffc\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:34:32Z\",\"local\":{\"status\":200,\"duration\":\"154.69Âµs\",\"request_id\":\"e0423d39-8486-4e82-8e02-dae4cd2e1ffc\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:35:32Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"c6fc0260-7555-45e9-b02e-c9adcd61493e\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-17T06:35:32Z\",\"local\":{\"status\":200,\"duration\":\"150.55Âµs\",\"request_id\":\"c6fc0260-7555-45e9-b02e-c9adcd61493e\"}}\n",
  "anonymousoverflow": "",
  "searxng": "SearXNG 2026.1.16-2d9f213ca\nUpdating certificates in /etc/ssl/certs...\n0 added, 0 removed; done.\nRunning hooks in /etc/ca-certificates/update.d...\ndone.\n[INFO] Starting granian (main PID: 1)\n[INFO] Listening at: http://:::8080\n[INFO] Spawning worker-1 with PID: 923\n2026-01-17 06:32:49,876 ERROR:searx.engines: loading engine ahmia failed: set engine to inactive!\n2026-01-17 06:32:50,073 ERROR:searx.engines: loading engine torch failed: set engine to inactive!\n2026-01-17 06:32:50,134 WARNING:searx.botdetection.config: missing config file: /etc/searxng/limiter.toml\n[INFO] Started worker-1\n",
  "rimgo": "\n â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” \n â”‚                  Fiber v2.52.10                   â”‚ \n â”‚               http://127.0.0.1:3002               â”‚ \n â”‚       (bound on host 0.0.0.0 and port 3002)       â”‚ \n â”‚                                                   â”‚ \n â”‚ Handlers ............ 57  Processes ........... 1 â”‚ \n â”‚ Prefork ....... Disabled  PID ................. 1 â”‚ \n â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ \n\n",
  "cobalt": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/17 06:32:33 [notice] 1#1: using the \"epoll\" event method\n2026/01/17 06:32:33 [notice] 1#1: nginx/1.29.4\n2026/01/17 06:32:33 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/17 06:32:33 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/17 06:32:33 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/17 06:32:33 [notice] 1#1: start worker processes\n2026/01/17 06:32:33 [notice] 1#1: start worker process 30\n2026/01/17 06:32:33 [notice] 1#1: start worker process 31\n2026/01/17 06:32:33 [notice] 1#1: start worker process 32\n2026/01/17 06:32:33 [notice] 1#1: start worker process 33\n",
  "memos": "2026/01/17 06:32:34 WARN failed to find migration history in pre-migrate error=\"SQL logic error: no such table: migration_history (1)\"\n---\nServer profile\nversion: 0.24.0\ndata: /var/opt/memos\ndsn: /var/opt/memos/memos_prod.db\naddr: \nport: 5230\nmode: prod\ndriver: sqlite\n---\nVersion 0.24.0 has been started on port 5230\n---\nSee more in:\nðŸ‘‰Website: https://usememos.com\nðŸ‘‰GitHub: https://github.com/usememos/memos\n---\n\nâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•\nâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘\nâ–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘\nâ•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•\n",
  "portainer": "\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[31mWRN\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cli/cli.go:168\u001b[0m\u001b[36m >\u001b[0m the --no-analytics flag has been kept to allow migration of instances running a previous version of Portainer with this flag enabled, to version 2.0 where enabling this flag will have no effect |\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:325\u001b[0m\u001b[36m >\u001b[0m encryption key file not present | \u001b[36mfilename=\u001b[0m/run/secrets/portainer\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:365\u001b[0m\u001b[36m >\u001b[0m proceeding without encryption key |\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/database/boltdb/db.go:137\u001b[0m\u001b[36m >\u001b[0m loading PortainerDB | \u001b[36mfilename=\u001b[0mportainer.db\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/internal/ssl/ssl.go:79\u001b[0m\u001b[36m >\u001b[0m no cert files found, generating self signed SSL certificates |\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:507\u001b[0m\u001b[36m >\u001b[0m created admin user with the given password. |\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/chisel/service.go:228\u001b[0m\u001b[36m >\u001b[0m generated a new Chisel private key file | \u001b[36mprivate-key=\u001b[0m/data/chisel/private-key.pem\n2026/01/17 06:32:35 server: Reverse tunnelling enabled\n2026/01/17 06:32:35 server: Fingerprint egaXg4pv7KFMlMt0xNnNFg9LqTqZmXARka8o1u/5IFE=\n2026/01/17 06:32:35 server: Listening on http://0.0.0.0:8000\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:636\u001b[0m\u001b[36m >\u001b[0m starting Portainer | \u001b[36mbuild_number=\u001b[0m251 \u001b[36mgo_version=\u001b[0m1.24.11 \u001b[36mimage_tag=\u001b[0m2.33.6-linux-amd64 \u001b[36mnodejs_version=\u001b[0m18.20.8 \u001b[36mversion=\u001b[0m2.33.6 \u001b[36mwebpack_version=\u001b[0m5.88.2 \u001b[36myarn_version=\u001b[0m1.22.22\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:351\u001b[0m\u001b[36m >\u001b[0m starting HTTP server | \u001b[36mbind_address=\u001b[0m:9000\n\u001b[90m2026/01/17 06:32AM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:367\u001b[0m\u001b[36m >\u001b[0m starting HTTPS server | \u001b[36mbind_address=\u001b[0m:9443\n",
  "wg-easy": "2026-01-17T06:31:20.792Z Server Listening on http://0.0.0.0:51821\n2026-01-17T06:31:20.803Z WireGuard Loading configuration...\n$ wg genkey\n$ echo ***hidden*** | wg pubkey\n2026-01-17T06:31:20.821Z WireGuard Configuration generated.\n2026-01-17T06:31:20.822Z WireGuard Config saving...\n2026-01-17T06:31:20.823Z WireGuard Config saved.\n$ wg-quick down wg0\n$ wg-quick up wg0\n2026-01-17T06:31:21.092Z WireGuard Config syncing...\n$ wg syncconf wg0 <(wg-quick strip wg0)\n2026-01-17T06:31:21.145Z WireGuard Config synced.\n",
  "odido-booster": "INFO:odido.service:Service initialized\n/app/app/main.py:43: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"startup\")\n/app/app/main.py:48: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"shutdown\")\nINFO:odido.service:Odido API not configured - skipping remaining data sync\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nINFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8085 (Press CTRL+C to quit)\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:All renewal attempts failed - check Odido API credentials and network connectivity\nINFO:     127.0.0.1:53620 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:48920 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51386 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:36290 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:49218 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:45302 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:51698 - \"GET /docs HTTP/1.1\" 200 OK\n",
  "vert": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: /etc/nginx/conf.d/default.conf differs from the packaged version\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/17 06:33:08 [notice] 1#1: using the \"epoll\" event method\n2026/01/17 06:33:08 [notice] 1#1: nginx/1.28.1\n2026/01/17 06:33:08 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/17 06:33:08 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/17 06:33:08 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/17 06:33:08 [notice] 1#1: start worker processes\n2026/01/17 06:33:08 [notice] 1#1: start worker process 29\n2026/01/17 06:33:08 [notice] 1#1: start worker process 30\n2026/01/17 06:33:08 [notice] 1#1: start worker process 31\n2026/01/17 06:33:08 [notice] 1#1: start worker process 32\n127.0.0.1 - - [17/Jan/2026:06:33:13 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:33:43 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:34:13 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:34:43 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:35:13 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:35:43 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [17/Jan/2026:06:36:13 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n",
  "immich": "\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:11 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m110000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:11 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m120000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:11 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m130000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:15 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m140000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:15 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m150000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:15 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m160000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:15 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m170000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:15 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m180000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:18 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m190000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:18 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m200000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:18 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32mSuccessfully imported 219997 geodata records in 20.68s (10639 records/second)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32mGeodata import completed\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MetadataService]\u001b[39m \u001b[32mInitialized local reverse geocoder\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mPlugin immich-core is up to date (version 2.0.0). Skipping\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully processed core plugin: immich-core (version 2.0.0)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully loaded plugin: immich-core\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:ServerService]\u001b[39m \u001b[32mFeature Flags: {\n  \"smartSearch\": true,\n  \"facialRecognition\": true,\n  \"duplicateDetection\": true,\n  \"map\": true,\n  \"reverseGeocoding\": true,\n  \"importFaces\": false,\n  \"sidecar\": true,\n  \"search\": true,\n  \"trash\": true,\n  \"oauth\": false,\n  \"oauthAutoLaunch\": false,\n  \"ocr\": true,\n  \"passwordLogin\": true,\n  \"configFile\": false,\n  \"email\": false\n}\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:SystemConfigService]\u001b[39m \u001b[32mLogLevel=log (set via system config)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MachineLearningRepository]\u001b[39m \u001b[32mMachine learning server became healthy (http://127.0.0.1:3003).\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestFactory]\u001b[39m \u001b[32mStarting Nest application...\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsCommonModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyCoreModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mDiscoveryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryCoreModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsRootModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mMicroservicesModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestApplication]\u001b[39m \u001b[32mNest application successfully started\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/17/2026, 6:33:30 AM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:Bootstrap]\u001b[39m \u001b[32mImmich Microservices is running [v2.4.1] [production] \u001b[39m\n",
  "wikiless": "Wikiless 10.0.0.72:8180 running on http://0.0.0.0:8180\nCleared cached static media files. You can turn this off by setting the config.cache_control to false.\nFetched https://en.wikipedia.org/?useskin=vector from Wikipedia.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\n",
  "unbound": "[1768631481] unbound[1:0] warning: so-sndbuf 4194304 was not granted. Got 425984. To fix: start with root permissions(linux) or sysctl bigger net.core.wmem_max(linux) or kern.ipc.maxsockbuf(bsd) values. or set so-sndbuf: 0 (use system value).\n",
  "gluetun": "|   â”œâ”€â”€ Log: no\n|   â”œâ”€â”€ Read header timeout: 1s\n|   â””â”€â”€ Read timeout: 3s\nâ”œâ”€â”€ Control server settings:\n|   â”œâ”€â”€ Listening address: :8000\n|   â”œâ”€â”€ Logging: yes\n|   â””â”€â”€ Authentication file path: /gluetun/auth/config.toml\nâ”œâ”€â”€ Storage settings:\n|   â””â”€â”€ Filepath: /gluetun/servers.json\nâ”œâ”€â”€ OS Alpine settings:\n|   â”œâ”€â”€ Process UID: 1000\n|   â””â”€â”€ Process GID: 1000\nâ”œâ”€â”€ Public IP settings:\n|   â”œâ”€â”€ IP file path: /tmp/gluetun/ip\n|   â”œâ”€â”€ Public IP data base API: ipinfo\n|   â””â”€â”€ Public IP data backup APIs:\n|       â”œâ”€â”€ ifconfigco\n|       â”œâ”€â”€ ip2location\n|       â””â”€â”€ cloudflare\nâ””â”€â”€ Version settings:\n    â””â”€â”€ Enabled: yes\n2026-01-17T06:31:21Z INFO [routing] default route found: interface eth0, gateway 172.20.0.1, assigned IP 172.20.0.254 and family v4\n2026-01-17T06:31:21Z INFO [routing] adding route for 0.0.0.0/0\n2026-01-17T06:31:21Z INFO [firewall] setting allowed subnets...\n2026-01-17T06:31:21Z INFO [routing] default route found: interface eth0, gateway 172.20.0.1, assigned IP 172.20.0.254 and family v4\n2026-01-17T06:31:21Z INFO [routing] adding route for 172.20.0.0/16\n2026-01-17T06:31:21Z INFO [dns] using plaintext DNS at address 9.9.9.9\n2026-01-17T06:31:21Z INFO [healthcheck] listening on 127.0.0.1:9999\n2026-01-17T06:31:21Z INFO [http proxy] listening on :8888\n2026-01-17T06:31:21Z INFO [http server] http server listening on [::]:8000\n2026-01-17T06:31:21Z INFO [firewall] allowing VPN connection...\n2026-01-17T06:31:21Z INFO [wireguard] Using available kernelspace implementation\n2026-01-17T06:31:21Z INFO [wireguard] Connecting to 80.79.7.101:51820\n2026-01-17T06:31:21Z INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 10416 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 8080 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 8081 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 8085 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 8180 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 3000 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 3002 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 8280 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 8480 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 80 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 24153 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 8282 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 9000 through interface tun0...\n2026-01-17T06:31:21Z INFO [firewall] setting allowed input port 2283 through interface tun0...\n2026-01-17T06:31:22Z INFO [ip getter] Public IP address is 80.79.7.119 (Netherlands, South Holland, Naaldwijk - source: ipinfo+ifconfig.co+ip2location+cloudflare)\n2026-01-17T06:31:22Z INFO [vpn] You are running on the bleeding edge of latest!\n",
  "companion": "    use_unix_socket: false,\n    unix_socket_path: \"/tmp/invidious-companion.sock\",\n    base_path: \"/companion\",\n    secret_key: \"AQkxECAnIdrufWQJ\",\n    verify_requests: false,\n    encrypt_query_params: false,\n    enable_metrics: false\n  },\n  cache: { enabled: true, directory: \"/var/tmp\" },\n  networking: {\n    proxy: null,\n    ipv6_block: null,\n    fetch: {\n      timeout_ms: 30000,\n      retry: {\n        enabled: false,\n        times: 1,\n        initial_debounce: 0,\n        debounce_multiplier: 0\n      }\n    },\n    videoplayback: { ump: false, video_fetch_chunk_size_mb: 5 }\n  },\n  jobs: {\n    youtube_session: { po_token_enabled: true, frequency: \"*/5 * * * *\" }\n  },\n  youtube_session: { oauth_enabled: false, cookies: \"\" }\n}\n[INFO] Using Invidious companion version 2026.01.13-cd52e7f\n[INFO] job po_token is active.\n[INFO] Starting PO token generation in background...\n[INFO] Server successfully started at http://0.0.0.0:8282/companion\n[INFO] the \"Not implemented: HTMLCanvasElement.prototype.getContext\" error is normal. Please do not open a bug report about it.\nError: Not implemented: HTMLCanvasElement.prototype.getContext (without installing the canvas npm package)\n    at module.exports (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/browser/not-implemented.js:9:17)\n    at HTMLCanvasElementImpl.getContext (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/living/nodes/HTMLCanvasElement-impl.js:42:5)\n    at HTMLCanvasElement.getContext (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/living/generated/HTMLCanvasElement.js:131:58)\n    at eval (eval at <anonymous> (eval at <anonymous> (eval at <anonymous> (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9))))), <anonymous>:1:182)\n    at eK (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:4335:30822)\n    at W.eval [as N] (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:4335:55119)\n    at IH (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:4335:32300)\n    at bD (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:4335:1702)\n    at y (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:4335:15308)\n    at $Z (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:4335:22797) undefined\n[INFO] Searching for videos to validate PO token\n[INFO] Validating PO token with video: fYSXB7Vde10\n[WARNING] No URLs found for adaptive formats. Falling back to other YT clients.\n[WARNING] Trying fallback YT client TV_SIMPLY\n[INFO] Successfully validated PO token with video: fYSXB7Vde10\n[INFO] Successfully generated PO token\n",
  "vertd": "[2026-01-17T06:32:32Z INFO  vertd] starting vertd\n[2026-01-17T06:32:39Z INFO  vertd] working w/ ffmpeg 6.1.1-3ubuntu5 and ffprobe 6.1.1-3ubuntu5\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] *******\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] you're running vertd on a docker container, but no GPU was detected.\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] this usually is because you're running Docker under WSL or because\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] you are not passing the GPU device correctly.\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] \n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] if this doesn't seem right, make sure to provide the following info when\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] asking for help:\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] - adapter name: llvmpipe (LLVM 20.1.2, 256 bits)\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] - adapter vendor: 0x10005\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] - backend: vulkan\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] - device ID: 0\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] - device type: Cpu\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] - driver: llvmpipe\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] - driver info: Mesa 25.0.7-0ubuntu0.24.04.2 (LLVM 20.1.2)\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] \n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] vertd will fall back to CPU rendering to ensure conversions can still proceed.\n[2026-01-17T06:32:41Z WARN  vertd::converter::gpu] *******\n[2026-01-17T06:32:41Z INFO  vertd] using CPU rendering (software encoding) -- this will be slower than GPU acceleration\n[2026-01-17T06:32:41Z INFO  vertd::http] http server listening on 0.0.0.0:24153\n",
  "watchtower": "time=\"2026-01-17T06:32:33Z\" level=info msg=\"Watchtower 1.7.1\"\ntime=\"2026-01-17T06:32:33Z\" level=info msg=\"Using notifications: generic+http\"\ntime=\"2026-01-17T06:32:33Z\" level=info msg=\"Checking all containers (except explicitly disabled with label)\"\ntime=\"2026-01-17T06:32:33Z\" level=info msg=\"Scheduling first run: 2026-01-17 07:32:33 +0000 UTC\"\ntime=\"2026-01-17T06:32:33Z\" level=info msg=\"Note that the first check will be performed in 59 minutes, 59 seconds\"\n",
  "invidious-db": "2026-01-17 06:32:38.257 UTC [50] LOG:  database system was shut down at 2026-01-17 06:32:36 UTC\n2026-01-17 06:32:38.285 UTC [49] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init-invidious-db.sh\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE TYPE\nCREATE TABLE\nGRANT\nCREATE TABLE\nGRANT\n\nwaiting for server to shut down....2026-01-17 06:32:41.615 UTC [49] LOG:  received fast shutdown request\n2026-01-17 06:32:41.625 UTC [49] LOG:  aborting any active transactions\n2026-01-17 06:32:41.631 UTC [49] LOG:  background worker \"logical replication launcher\" (PID 56) exited with exit code 1\n2026-01-17 06:32:41.638 UTC [51] LOG:  shutting down\n2026-01-17 06:32:41.705 UTC [49] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-17 06:32:41.752 UTC [1] LOG:  starting PostgreSQL 14.20 (Debian 14.20-1.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n2026-01-17 06:32:41.753 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-17 06:32:41.753 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-17 06:32:41.763 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-17 06:32:41.772 UTC [83] LOG:  database system was shut down at 2026-01-17 06:32:41 UTC\n2026-01-17 06:32:41.780 UTC [1] LOG:  database system is ready to accept connections\n",
  "wikiless-redis": "1:C 17 Jan 2026 06:32:33.064 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 17 Jan 2026 06:32:33.064 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 17 Jan 2026 06:32:33.064 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 17 Jan 2026 06:32:33.064 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 17 Jan 2026 06:32:33.066 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 17 Jan 2026 06:32:33.066 * monotonic clock: POSIX clock_gettime\n1:M 17 Jan 2026 06:32:33.068 * Running mode=standalone, port=6379.\n1:M 17 Jan 2026 06:32:33.068 * Server initialized\n1:M 17 Jan 2026 06:32:33.075 * Ready to accept connections tcp\n",
  "searxng-redis": "1:C 17 Jan 2026 06:32:33.064 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 17 Jan 2026 06:32:33.065 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 17 Jan 2026 06:32:33.065 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 17 Jan 2026 06:32:33.065 * Configuration loaded\n1:M 17 Jan 2026 06:32:33.065 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 17 Jan 2026 06:32:33.066 * monotonic clock: POSIX clock_gettime\n1:M 17 Jan 2026 06:32:33.068 * Running mode=standalone, port=6379.\n1:M 17 Jan 2026 06:32:33.068 * Server initialized\n1:M 17 Jan 2026 06:32:33.072 * Ready to accept connections tcp\n",
  "immich-db": "selecting default shared_buffers ... 128MB\nselecting default time zone ... Etc/UTC\ncreating configuration files ... ok\nrunning bootstrap script ... ok\nperforming post-bootstrap initialization ... ok\nsyncing data to disk ... ok\n\n\nSuccess. You can now start the database server using:\n\n    pg_ctl -D /var/lib/postgresql/data -l logfile start\n\ninitdb: warning: enabling \"trust\" authentication for local connections\nYou can change this by editing pg_hba.conf or using the option -A, or\n--auth-local and --auth-host, the next time you run initdb.\n2026-01-17 06:32:40.175 GMT [55] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:32:40.176 GMT [55] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\nwaiting for server to start....2026-01-17 06:32:40.225 GMT [60] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:32:40.225 GMT [60] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:32:40.387 UTC [60] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-17 06:32:40.390 UTC [60] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-17 06:32:40.428 UTC [61] LOG:  database system was shut down at 2026-01-17 06:32:38 UTC\n2026-01-17 06:32:40.443 UTC [60] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*\n\n2026-01-17 06:32:41.301 UTC [60] LOG:  received fast shutdown request\nwaiting for server to shut down....2026-01-17 06:32:41.305 UTC [60] LOG:  aborting any active transactions\n2026-01-17 06:32:41.312 UTC [60] LOG:  background worker \"logical replication launcher\" (PID 68) exited with exit code 1\n2026-01-17 06:32:41.315 UTC [63] LOG:  shutting down\n2026-01-17 06:32:41.348 UTC [60] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-17 06:32:41.452 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:32:41.452 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-17 06:32:41.500 UTC [1] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-17 06:32:41.500 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-17 06:32:41.500 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-17 06:32:41.504 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-17 06:32:41.517 UTC [78] LOG:  database system was shut down at 2026-01-17 06:32:41 UTC\n2026-01-17 06:32:41.552 UTC [1] LOG:  database system is ready to accept connections\n2026-01-17 06:32:51.605 UTC [96] ERROR:  relation \"system_metadata\" does not exist at character 21\n2026-01-17 06:32:51.605 UTC [96] STATEMENT:  select \"value\" from \"system_metadata\" where \"key\" = $1\n",
  "immich-redis": "1:M 17 Jan 2026 06:32:33.161 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:M 17 Jan 2026 06:32:33.161 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo\n1:M 17 Jan 2026 06:32:33.161 * Valkey version=9.0.1, bits=64, commit=00000000, modified=0, pid=1, just started\n1:M 17 Jan 2026 06:32:33.161 # Warning: no config file specified, using the default config. In order to specify a config file use valkey-server /path/to/valkey.conf\n1:M 17 Jan 2026 06:32:33.172 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 17 Jan 2026 06:32:33.173 * monotonic clock: POSIX clock_gettime\n1:M 17 Jan 2026 06:32:33.236 * Running mode=standalone, port=6379.\n1:M 17 Jan 2026 06:32:33.256 * Server initialized\n1:M 17 Jan 2026 06:32:33.256 * Ready to accept connections tcp\n",
  "immich-ml": "\u001b[2;36m[01/17/26 06:32:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting gunicorn \u001b[1;36m23.0\u001b[0m.\u001b[1;36m0\u001b[0m                           \n\u001b[2;36m[01/17/26 06:32:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening at: \u001b[4;94mhttp://\u001b[0m\u001b[1m[\u001b[0m::\u001b[1m]\u001b[0m:\u001b[1;36m3003\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m                \n\u001b[2;36m[01/17/26 06:32:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using worker: immich_ml.config.CustomUvicornWorker \n\u001b[2;36m[01/17/26 06:32:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Booting worker with pid: \u001b[1;36m15\u001b[0m                        \n\u001b[2;36m[01/17/26 06:32:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started server process \u001b[1m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m                        \n\u001b[2;36m[01/17/26 06:32:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Waiting for application startup.                   \n\u001b[2;36m[01/17/26 06:32:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created in-memory cache with unloading after 300s  \n\u001b[2;36m                    \u001b[0m         of inactivity.                                     \n\u001b[2;36m[01/17/26 06:32:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized request thread pool with \u001b[1;36m4\u001b[0m threads.    \n\u001b[2;36m[01/17/26 06:32:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Application startup complete.                      \n"
}