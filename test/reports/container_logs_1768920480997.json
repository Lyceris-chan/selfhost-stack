{
  "dashboard": "2026/01/20 14:44:04 [notice] 1#1: start worker process 21\n2026/01/20 14:44:04 [notice] 1#1: start worker process 22\n2026/01/20 14:44:04 [notice] 1#1: start worker process 23\n2026/01/20 14:44:04 [notice] 1#1: start worker process 24\n10.0.1.187 - - [20/Jan/2026:14:44:06 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:06 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:06 [info] 21#21: *1 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:08 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:08 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:08 [info] 22#22: *3 client 10.0.1.187 closed keepalive connection\n2026/01/20 14:44:10 [info] 23#23: *5 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:10 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:10 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.1.187 - - [20/Jan/2026:14:44:12 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:12 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:12 [info] 24#24: *7 client 10.0.1.187 closed keepalive connection\n2026/01/20 14:44:14 [info] 21#21: *9 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:14 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:14 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n10.0.1.187 - - [20/Jan/2026:14:44:16 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:16 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:16 [info] 21#21: *11 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:18 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:18 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:18 [info] 21#21: *13 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:20 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:20 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:20 [info] 21#21: *15 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:22 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:22 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:22 [info] 21#21: *17 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:24 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:24 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:24 [info] 21#21: *19 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:26 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:26 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:26 [info] 21#21: *21 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:28 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:28 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:28 [info] 21#21: *23 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:30 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:30 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:30 [info] 21#21: *25 client 10.0.1.187 closed keepalive connection\n10.0.1.187 - - [20/Jan/2026:14:44:32 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\" \"-\"\n10.0.1.187 - - [20/Jan/2026:14:44:32 +0000] \"GET /api/status HTTP/1.1\" 404 22 \"-\" \"curl/8.5.0\"\n2026/01/20 14:44:32 [info] 21#21: *27 client 10.0.1.187 closed keepalive connection\n127.0.0.1 - - [20/Jan/2026:14:44:34 +0000] \"GET / HTTP/1.1\" 200 269296 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:44:34 +0000] \"GET / HTTP/1.1\" 200 269296 \"-\" \"Wget\"\n127.0.0.1 - - [20/Jan/2026:14:45:04 +0000] \"GET / HTTP/1.1\" 200 269296 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:45:04 +0000] \"GET / HTTP/1.1\" 200 269296 \"-\" \"Wget\"\n",
  "api": "INFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:55555 (Press CTRL+C to quit)\nINFO:     127.0.0.1:37440 - \"GET /api/health HTTP/1.1\" 200 OK\n[INFO] Watchtower Notification (Plain): Watchtower 1.7.1\nUsing notifications: generic+http\nChecking all containers (except explicitly disabled with label)\nScheduling first run: 2026-01-20 15:44:05 +0000 UTC\nNote that the first check will be performed in 59 minutes, 59 seconds\n\nINFO:     172.18.0.5:38220 - \"POST /watchtower?token=tpiUYvszGAzDehuciYas07BIn6YtDoxS HTTP/1.1\" 200 OK\nINFO:     172.20.0.9:52286 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:52288 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:52304 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:52316 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:52318 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:42092 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:42100 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:42112 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:42114 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:37308 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     172.20.0.9:42120 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:48922 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:48936 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:48942 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     172.20.0.9:48952 - \"GET /status HTTP/1.0\" 404 Not Found\nINFO:     127.0.0.1:36084 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:57344 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:34628 - \"GET /api/health HTTP/1.1\" 200 OK\nINFO:     10.0.1.187:40256 - \"GET /api/services HTTP/1.1\" 200 OK\nINFO:     10.0.1.187:40240 - \"GET /api/containers HTTP/1.1\" 200 OK\nINFO:     10.0.1.187:40256 - \"GET /api/metrics HTTP/1.1\" 200 OK\nINFO:     10.0.1.187:40240 - \"GET /api/containers HTTP/1.1\" 200 OK\nINFO:     10.0.1.187:40256 - \"GET /api/metrics HTTP/1.1\" 200 OK\n[INFO] Certificate check successful: Self-Signed for 10.0.1.187\n",
  "adguard": "2026/01/20 14:43:37.837024 [info] starting adguard home version=\"AdGuard Home, version v0.107.71\"\n2026/01/20 14:43:37.844490 [info] config_migrator: upgrade yaml from=29 to=30\n2026/01/20 14:43:37.844509 [info] config_migrator: upgrade yaml from=30 to=31\n2026/01/20 14:43:37.844515 [info] config_migrator: upgrade yaml from=31 to=32\n2026/01/20 14:43:37.873752 [info] dhcpd: warning: creating dhcpv4 server err=\"dhcpv4: invalid IP is not an IPv4 address\"\n2026/01/20 14:43:37.882007 [info] tls_manager: using default ciphers\n2026/01/20 14:43:37.882248 [info] tls_manager: parsing multiple pem certificates num=1\n2026/01/20 14:43:38.062601 [info] webapi: initializing\n2026/01/20 14:43:38.073148 [info] warning: private rdns resolution failed; disabling err=\"preparing resolvers: no upstream specified\"\n2026/01/20 14:43:38.073384 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/20 14:43:38.073443 [info] dnsproxy: cache enabled size=4096\n2026/01/20 14:43:38.073618 [info] dnsproxy: max goroutines is set count=300\n2026/01/20 14:43:38.073753 [info] dnsproxy: ratelimit is enabled rps=20 ipv4_subnet_mask_len=24 ipv6_subnet_mask_len=56\n2026/01/20 14:43:38.073763 [info] dnsproxy: server will refuse requests of type any\n2026/01/20 14:43:38.073770 [info] dnsproxy: upstream mode is set mode=load_balance\n2026/01/20 14:43:38.073776 [info] dnsproxy: cache enabled size=4194304\n2026/01/20 14:43:38.073784 [info] dnsproxy: max goroutines is set count=300\n2026/01/20 14:43:38.075620 [info] addrproc: processing addresses\n2026/01/20 14:43:38.079155 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work\n2026/01/20 14:43:38.079239 [info] permcheck: changed permissions type=file path=/opt/adguardhome/conf/AdGuardHome.yaml\n2026/01/20 14:43:38.079299 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data\n2026/01/20 14:43:38.079358 [info] permcheck: changed permissions type=directory path=/opt/adguardhome/work/data/filters\n2026/01/20 14:43:38.079394 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/sessions.db\n2026/01/20 14:43:38.079515 [info] permcheck: changed permissions type=file path=/opt/adguardhome/work/data/stats.db\n2026/01/20 14:43:38.079610 [info] webapi: AdGuard Home is available at the following addresses:\n2026/01/20 14:43:38.081208 [info] go to http://127.0.0.1:8083\n2026/01/20 14:43:38.081266 [info] go to http://[::1]:8083\n2026/01/20 14:43:38.081288 [info] go to http://172.20.0.5:8083\n2026/01/20 14:43:38.082333 [info] starting plain server server=plain addr=0.0.0.0:8083\n2026/01/20 14:43:38.083463 [info] go to https://10.0.1.187:443\n2026/01/20 14:43:38.083545 [info] starting https server server=https\n2026/01/20 14:43:38.087159 [info] dnsproxy: starting dns proxy server\n2026/01/20 14:43:38.087221 [info] dnsproxy: creating udp server socket addr=0.0.0.0:53\n2026/01/20 14:43:38.087331 [info] dnsproxy: listening to udp addr=[::]:53\n2026/01/20 14:43:38.087344 [info] dnsproxy: creating tcp server socket addr=0.0.0.0:53\n2026/01/20 14:43:38.087394 [info] dnsproxy: listening to tcp addr=[::]:53\n2026/01/20 14:43:38.087403 [info] dnsproxy: creating tls server socket addr=0.0.0.0:853\n2026/01/20 14:43:38.087436 [info] dnsproxy: listening to tls addr=[::]:853\n2026/01/20 14:43:38.087445 [info] dnsproxy: creating quic listener addr=0.0.0.0:853\n2026/01/20 14:43:38.087571 failed to sufficiently increase receive buffer size (was: 1024 kiB, wanted: 7168 kiB, got: 2048 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n2026/01/20 14:43:38.087690 [info] dnsproxy: listening quic addr=[::]:853\n2026/01/20 14:43:38.088552 [info] dnsproxy: entering listener loop proto=tcp addr=[::]:53\n2026/01/20 14:43:38.088726 [info] dnsproxy: entering listener loop proto=tls addr=[::]:853\n2026/01/20 14:43:38.088901 [info] dnsproxy: entering dns-over-quic listener loop addr=[::]:853\n2026/01/20 14:43:38.088968 [info] dnsproxy: entering udp listener loop addr=[::]:53\n2026/01/20 14:44:06.389816 [info] filtering: saving contents id=1 path=/opt/adguardhome/work/data/filters/1.txt\n2026/01/20 14:44:06.590563 [info] filtering: filter updated id=1 bytes_written=40434673 rules_count=2000969\n2026/01/20 14:44:06.590597 [info] filtering: updated filter id=1 rules_count=2000969 prev_rules_count=0\n",
  "invidious": "[production] Invidious is ready to lead at http://0.0.0.0:3000\n2026-01-20 14:43:48 UTC [info] jobs: running ClearExpiredItems job\n2026-01-20 14:43:48 UTC [info] jobs: ClearExpiredItems done.\n2026-01-20 14:43:49 UTC [info] InstanceListRefreshJob: Done, sleeping for 30 minutes\n2026-01-20 14:44:18 UTC [info] 200 GET /api/v1/stats 127.27ms\n2026-01-20 14:44:48 UTC [info] 200 GET /api/v1/stats 90.46Âµs\n2026-01-20 14:45:18 UTC [info] 200 GET /api/v1/stats 74.25Âµs\n",
  "breezewiki": "note: config file not detected, using defaults\nnote: 1 items loaded from environment variables\nYour Web application is running at http://localhost:10416.\nStop this program at any time to terminate the Web Server.\n",
  "redlib": " ERROR redlib::client > Got an invalid response from reddit expected value at line 1 column 1. Status code: 403 Forbidden\nRate limit check failed: Failed to parse page JSON data: expected value at line 1 column 1 | /r/reddit/hot.json?&raw_json=1\nThis may cause issues with the rate limit.\nPlease report this error with the above information.\nhttps://github.com/redlib-org/redlib/issues/new?assignees=sigaloid&labels=bug&title=%F0%9F%90%9B+Bug+Report%3A+Rate+limit+mismatch\nStarting Redlib...\nRunning Redlib v0.36.0 on [::]:8081!\n",
  "scribe": "{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T14:44:43Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"a8c1fce8-ebf8-4eda-89a7-853c91bff4df\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T14:44:43Z\",\"local\":{\"status\":200,\"duration\":\"25.07ms\",\"request_id\":\"a8c1fce8-ebf8-4eda-89a7-853c91bff4df\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T14:45:43Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"4c67eb5f-f6fa-402d-804a-bd7be67c9b16\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T14:45:43Z\",\"local\":{\"status\":200,\"duration\":\"127.76Âµs\",\"request_id\":\"4c67eb5f-f6fa-402d-804a-bd7be67c9b16\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T14:46:43Z\",\"local\":{\"method\":\"GET\",\"path\":\"/\",\"request_id\":\"54b227c1-bd84-4cb9-8d99-816e994cbf58\"}}\n{\"severity\":\"Info\",\"source\":\"lucky\",\"timestamp\":\"2026-01-20T14:46:43Z\",\"local\":{\"status\":200,\"duration\":\"183.06Âµs\",\"request_id\":\"54b227c1-bd84-4cb9-8d99-816e994cbf58\"}}\n",
  "anonymousoverflow": "",
  "searxng": "SearXNG 2026.1.20-410996df9\nUpdating certificates in /etc/ssl/certs...\n0 added, 0 removed; done.\nRunning hooks in /etc/ca-certificates/update.d...\ndone.\n[INFO] Starting granian (main PID: 1)\n[INFO] Listening at: http://:::8080\n[INFO] Spawning worker-1 with PID: 923\n2026-01-20 14:43:59,181 ERROR:searx.engines: loading engine ahmia failed: set engine to inactive!\n2026-01-20 14:43:59,690 ERROR:searx.engines: loading engine torch failed: set engine to inactive!\n2026-01-20 14:44:00,006 WARNING:searx.botdetection.config: missing config file: /etc/searxng/limiter.toml\n[INFO] Started worker-1\n",
  "rimgo": "\n â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” \n â”‚                  Fiber v2.52.10                   â”‚ \n â”‚               http://127.0.0.1:3002               â”‚ \n â”‚       (bound on host 0.0.0.0 and port 3002)       â”‚ \n â”‚                                                   â”‚ \n â”‚ Handlers ............ 57  Processes ........... 1 â”‚ \n â”‚ Prefork ....... Disabled  PID ................. 1 â”‚ \n â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ \n\n",
  "cobalt": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/20 14:43:44 [notice] 1#1: using the \"epoll\" event method\n2026/01/20 14:43:44 [notice] 1#1: nginx/1.29.4\n2026/01/20 14:43:44 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/20 14:43:44 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/20 14:43:44 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/20 14:43:44 [notice] 1#1: start worker processes\n2026/01/20 14:43:44 [notice] 1#1: start worker process 30\n2026/01/20 14:43:44 [notice] 1#1: start worker process 31\n2026/01/20 14:43:44 [notice] 1#1: start worker process 32\n2026/01/20 14:43:44 [notice] 1#1: start worker process 33\n",
  "memos": "2026/01/20 14:43:36 WARN failed to find migration history in pre-migrate error=\"SQL logic error: no such table: migration_history (1)\"\n---\nServer profile\nversion: 0.24.0\ndata: /var/opt/memos\ndsn: /var/opt/memos/memos_prod.db\naddr: \nport: 5230\nmode: prod\ndriver: sqlite\n---\nVersion 0.24.0 has been started on port 5230\n---\nSee more in:\nðŸ‘‰Website: https://usememos.com\nðŸ‘‰GitHub: https://github.com/usememos/memos\n---\n\nâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•\nâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\nâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘\nâ–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘\nâ•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•\n",
  "portainer": "\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[31mWRN\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cli/cli.go:168\u001b[0m\u001b[36m >\u001b[0m the --no-analytics flag has been kept to allow migration of instances running a previous version of Portainer with this flag enabled, to version 2.0 where enabling this flag will have no effect |\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:325\u001b[0m\u001b[36m >\u001b[0m encryption key file not present | \u001b[36mfilename=\u001b[0m/run/secrets/portainer\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:365\u001b[0m\u001b[36m >\u001b[0m proceeding without encryption key |\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/database/boltdb/db.go:137\u001b[0m\u001b[36m >\u001b[0m loading PortainerDB | \u001b[36mfilename=\u001b[0mportainer.db\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/internal/ssl/ssl.go:79\u001b[0m\u001b[36m >\u001b[0m no cert files found, generating self signed SSL certificates |\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:507\u001b[0m\u001b[36m >\u001b[0m created admin user with the given password. |\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/chisel/service.go:228\u001b[0m\u001b[36m >\u001b[0m generated a new Chisel private key file | \u001b[36mprivate-key=\u001b[0m/data/chisel/private-key.pem\n2026/01/20 14:43:38 server: Reverse tunnelling enabled\n2026/01/20 14:43:38 server: Fingerprint n+cDXHfFVkWQtKQKBhV1gHi9VrKBDqnprtfGXj7WdRU=\n2026/01/20 14:43:38 server: Listening on http://0.0.0.0:8000\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/cmd/portainer/main.go:636\u001b[0m\u001b[36m >\u001b[0m starting Portainer | \u001b[36mbuild_number=\u001b[0m251 \u001b[36mgo_version=\u001b[0m1.24.11 \u001b[36mimage_tag=\u001b[0m2.33.6-linux-amd64 \u001b[36mnodejs_version=\u001b[0m18.20.8 \u001b[36mversion=\u001b[0m2.33.6 \u001b[36mwebpack_version=\u001b[0m5.88.2 \u001b[36myarn_version=\u001b[0m1.22.22\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:367\u001b[0m\u001b[36m >\u001b[0m starting HTTPS server | \u001b[36mbind_address=\u001b[0m:9443\n\u001b[90m2026/01/20 02:43PM\u001b[0m \u001b[32mINF\u001b[0m \u001b[1mgithub.com/portainer/portainer/api/http/server.go:351\u001b[0m\u001b[36m >\u001b[0m starting HTTP server | \u001b[36mbind_address=\u001b[0m:9000\n",
  "wg-easy": "2026-01-20T14:43:36.699Z Server Listening on http://0.0.0.0:51821\n2026-01-20T14:43:36.722Z WireGuard Loading configuration...\n$ wg genkey\n$ echo ***hidden*** | wg pubkey\n2026-01-20T14:43:36.778Z WireGuard Configuration generated.\n2026-01-20T14:43:36.778Z WireGuard Config saving...\n2026-01-20T14:43:36.785Z WireGuard Config saved.\n$ wg-quick down wg0\n$ wg-quick up wg0\n2026-01-20T14:43:37.191Z WireGuard Config syncing...\n$ wg syncconf wg0 <(wg-quick strip wg0)\n2026-01-20T14:43:37.242Z WireGuard Config synced.\n",
  "odido-booster": "INFO:odido.service:Service initialized\n/app/app/main.py:43: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"startup\")\n/app/app/main.py:48: DeprecationWarning: \n        on_event is deprecated, use lifespan event handlers instead.\n\n        Read more about it in the\n        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n        \n  @app.on_event(\"shutdown\")\nINFO:odido.service:Odido API not configured - skipping remaining data sync\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nINFO:     Started server process [1]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8085 (Press CTRL+C to quit)\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:Odido API not configured - auto-renewal disabled. Set ODIDO_USER_ID and ODIDO_TOKEN environment variables\nERROR:odido.service:All renewal attempts failed - check Odido API credentials and network connectivity\nINFO:     127.0.0.1:50122 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:59052 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:41992 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:40154 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:53704 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:35644 - \"GET /docs HTTP/1.1\" 200 OK\nINFO:     127.0.0.1:38058 - \"GET /docs HTTP/1.1\" 200 OK\n",
  "vert": "/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: /etc/nginx/conf.d/default.conf differs from the packaged version\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2026/01/20 14:43:42 [notice] 1#1: using the \"epoll\" event method\n2026/01/20 14:43:42 [notice] 1#1: nginx/1.28.1\n2026/01/20 14:43:42 [notice] 1#1: built by gcc 15.2.0 (Alpine 15.2.0) \n2026/01/20 14:43:42 [notice] 1#1: OS: Linux 6.8.0-1030-azure\n2026/01/20 14:43:42 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:1048576\n2026/01/20 14:43:42 [notice] 1#1: start worker processes\n2026/01/20 14:43:42 [notice] 1#1: start worker process 29\n2026/01/20 14:43:42 [notice] 1#1: start worker process 30\n2026/01/20 14:43:42 [notice] 1#1: start worker process 31\n2026/01/20 14:43:42 [notice] 1#1: start worker process 32\n127.0.0.1 - - [20/Jan/2026:14:43:47 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:44:17 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:44:47 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:45:17 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:45:47 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:46:18 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:46:48 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n127.0.0.1 - - [20/Jan/2026:14:47:18 +0000] \"GET / HTTP/1.1\" 200 26277 \"-\" \"Wget\" \"-\"\n",
  "immich": "\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:24 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m110000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:24 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m120000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:25 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m130000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:28 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m140000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:28 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m150000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:28 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m160000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:28 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m170000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:28 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m180000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:31 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m190000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:31 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32m200000 geodata records imported\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:31 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32mSuccessfully imported 219997 geodata records in 21.68s (10149 records/second)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MapRepository]\u001b[39m \u001b[32mGeodata import completed\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MetadataService]\u001b[39m \u001b[32mInitialized local reverse geocoder\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mPlugin immich-core is up to date (version 2.0.0). Skipping\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully processed core plugin: immich-core (version 2.0.0)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:PluginService]\u001b[39m \u001b[32mSuccessfully loaded plugin: immich-core\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:ServerService]\u001b[39m \u001b[32mFeature Flags: {\n  \"smartSearch\": true,\n  \"facialRecognition\": true,\n  \"duplicateDetection\": true,\n  \"map\": true,\n  \"reverseGeocoding\": true,\n  \"importFaces\": false,\n  \"sidecar\": true,\n  \"search\": true,\n  \"trash\": true,\n  \"oauth\": false,\n  \"oauthAutoLaunch\": false,\n  \"ocr\": true,\n  \"passwordLogin\": true,\n  \"configFile\": false,\n  \"email\": false\n}\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:SystemConfigService]\u001b[39m \u001b[32mLogLevel=log (set via system config)\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:MachineLearningRepository]\u001b[39m \u001b[32mMachine learning server became healthy (http://127.0.0.1:3003).\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestFactory]\u001b[39m \u001b[32mStarting Nest application...\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsCommonModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mKyselyCoreModule$1 dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mDiscoveryModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mOpenTelemetryCoreModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mClsRootModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mBullModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:InstanceLoader]\u001b[39m \u001b[32mMicroservicesModule dependencies initialized\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:NestApplication]\u001b[39m \u001b[32mNest application successfully started\u001b[39m\n\u001b[32m[Nest] 7  - \u001b[39m01/20/2026, 2:44:44 PM \u001b[32m    LOG\u001b[39m \u001b[33m[Microservices:Bootstrap]\u001b[39m \u001b[32mImmich Microservices is running [v2.4.1] [production] \u001b[39m\n",
  "wikiless": "Wikiless 10.0.1.187:8180 running on http://0.0.0.0:8180\nCleared cached static media files. You can turn this off by setting the config.cache_control to false.\nFetched https://en.wikipedia.org/?useskin=vector from Wikipedia.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\nGot key https://en.wikipedia.org/?useskin=vector from cache.\n",
  "unbound": "[1768920216] unbound[1:0] warning: so-sndbuf 4194304 was not granted. Got 425984. To fix: start with root permissions(linux) or sysctl bigger net.core.wmem_max(linux) or kern.ipc.maxsockbuf(bsd) values. or set so-sndbuf: 0 (use system value).\n",
  "gluetun": "|   â”œâ”€â”€ Listening address: :8000\n|   â”œâ”€â”€ Logging: yes\n|   â””â”€â”€ Authentication file path: /gluetun/auth/config.toml\nâ”œâ”€â”€ Storage settings:\n|   â””â”€â”€ Filepath: /gluetun/servers.json\nâ”œâ”€â”€ OS Alpine settings:\n|   â”œâ”€â”€ Process UID: 1000\n|   â””â”€â”€ Process GID: 1000\nâ”œâ”€â”€ Public IP settings:\n|   â”œâ”€â”€ IP file path: /tmp/gluetun/ip\n|   â”œâ”€â”€ Public IP data base API: ipinfo\n|   â””â”€â”€ Public IP data backup APIs:\n|       â”œâ”€â”€ ifconfigco\n|       â”œâ”€â”€ ip2location\n|       â””â”€â”€ cloudflare\nâ””â”€â”€ Version settings:\n    â””â”€â”€ Enabled: yes\n2026-01-20T14:43:38Z INFO [routing] default route found: interface eth0, gateway 172.20.0.1, assigned IP 172.20.0.254 and family v4\n2026-01-20T14:43:38Z INFO [routing] adding route for 0.0.0.0/0\n2026-01-20T14:43:38Z INFO [firewall] setting allowed subnets...\n2026-01-20T14:43:38Z INFO [routing] default route found: interface eth0, gateway 172.20.0.1, assigned IP 172.20.0.254 and family v4\n2026-01-20T14:43:38Z INFO [routing] adding route for 172.20.0.0/16\n2026-01-20T14:43:38Z INFO [dns] using plaintext DNS at address 9.9.9.9\n2026-01-20T14:43:38Z INFO [http server] http server listening on [::]:8000\n2026-01-20T14:43:38Z INFO [firewall] allowing VPN connection...\n2026-01-20T14:43:38Z INFO [healthcheck] listening on 127.0.0.1:9999\n2026-01-20T14:43:38Z INFO [http proxy] listening on :8888\n2026-01-20T14:43:38Z INFO [wireguard] Using available kernelspace implementation\n2026-01-20T14:43:38Z INFO [wireguard] Connecting to 80.79.7.101:51820\n2026-01-20T14:43:38Z INFO [wireguard] Wireguard setup is complete. Note Wireguard is a silent protocol and it may or may not work, without giving any error message. Typically i/o timeout errors indicate the Wireguard connection is not working.\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 10416 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 8080 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 8081 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 8085 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 8180 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 3000 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 3002 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 8280 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 8480 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 80 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 24153 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 8282 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 9000 through interface tun0...\n2026-01-20T14:43:38Z INFO [firewall] setting allowed input port 2283 through interface tun0...\n2026-01-20T14:43:39Z INFO [ip getter] Public IP address is 80.79.7.119 (Netherlands, South Holland, Naaldwijk - source: ipinfo+ifconfig.co+ip2location+cloudflare)\n2026-01-20T14:43:39Z INFO [vpn] You are running on the bleeding edge of latest!\n2026-01-20T14:45:24Z WARN [http server] route GET /v1/vpn/status is unprotected by default, please set up authentication following the documentation at https://github.com/qdm12/gluetun-wiki/blob/main/setup/advanced/control-server.md#authentication since this will become no longer publicly accessible after release v3.40.\n2026-01-20T14:45:24Z INFO [http server] 200 GET /v1/vpn/status wrote 21B to 127.0.0.1:47062 in 10.785337ms\n2026-01-20T14:45:24Z WARN [http server] route GET /v1/publicip/ip is unprotected by default, please set up authentication following the documentation at https://github.com/qdm12/gluetun-wiki/blob/main/setup/advanced/control-server.md#authentication since this will become no longer publicly accessible after release v3.40.\n2026-01-20T14:45:24Z INFO [http server] 200 GET /v1/publicip/ip wrote 263B to 127.0.0.1:47078 in 886.024Âµs\n",
  "companion": "    use_unix_socket: false,\n    unix_socket_path: \"/tmp/invidious-companion.sock\",\n    base_path: \"/companion\",\n    secret_key: \"6BdG1GrybTK9f9wy\",\n    verify_requests: false,\n    encrypt_query_params: false,\n    enable_metrics: false\n  },\n  cache: { enabled: true, directory: \"/var/tmp\" },\n  networking: {\n    proxy: null,\n    ipv6_block: null,\n    fetch: {\n      timeout_ms: 30000,\n      retry: {\n        enabled: false,\n        times: 1,\n        initial_debounce: 0,\n        debounce_multiplier: 0\n      }\n    },\n    videoplayback: { ump: false, video_fetch_chunk_size_mb: 5 }\n  },\n  jobs: {\n    youtube_session: { po_token_enabled: true, frequency: \"*/5 * * * *\" }\n  },\n  youtube_session: { oauth_enabled: false, cookies: \"\" }\n}\n[INFO] Using Invidious companion version 2026.01.13-cd52e7f\n[INFO] job po_token is active.\n[INFO] Starting PO token generation in background...\n[INFO] Server successfully started at http://0.0.0.0:8282/companion\n[INFO] the \"Not implemented: HTMLCanvasElement.prototype.getContext\" error is normal. Please do not open a bug report about it.\nError: Not implemented: HTMLCanvasElement.prototype.getContext (without installing the canvas npm package)\n    at module.exports (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/browser/not-implemented.js:9:17)\n    at HTMLCanvasElementImpl.getContext (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/living/nodes/HTMLCanvasElement-impl.js:42:5)\n    at HTMLCanvasElement.getContext (file:///tmp/deno-compile-invidious_companion/.deno_compile_node_modules/localhost/jsdom/26.1.0/lib/jsdom/living/generated/HTMLCanvasElement.js:131:58)\n    at eval (eval at <anonymous> (eval at <anonymous> (eval at <anonymous> (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9))))), <anonymous>:1:142)\n    at nB (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:428:36528)\n    at K.eval [as C] (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:428:55019)\n    at UC (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:428:23567)\n    at Lv (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:428:3412)\n    at n (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:428:2041)\n    at KB (eval at <anonymous> (eval at setup (file:///tmp/deno-compile-invidious_companion/src/lib/jobs/worker.ts:193:9)), <anonymous>:428:34266) undefined\n[INFO] Searching for videos to validate PO token\n[INFO] Validating PO token with video: uA7O6AJ7Qx4\n[WARNING] No URLs found for adaptive formats. Falling back to other YT clients.\n[WARNING] Trying fallback YT client TV_SIMPLY\n[INFO] Successfully validated PO token with video: uA7O6AJ7Qx4\n[INFO] Successfully generated PO token\n",
  "vertd": "[2026-01-20T14:43:36Z INFO  vertd] starting vertd\n[2026-01-20T14:43:39Z INFO  vertd] working w/ ffmpeg 6.1.1-3ubuntu5 and ffprobe 6.1.1-3ubuntu5\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] *******\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] you're running vertd on a docker container, but no GPU was detected.\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] this usually is because you're running Docker under WSL or because\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] you are not passing the GPU device correctly.\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] \n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] if this doesn't seem right, make sure to provide the following info when\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] asking for help:\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] - adapter name: llvmpipe (LLVM 20.1.2, 256 bits)\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] - adapter vendor: 0x10005\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] - backend: vulkan\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] - device ID: 0\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] - device type: Cpu\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] - driver: llvmpipe\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] - driver info: Mesa 25.0.7-0ubuntu0.24.04.2 (LLVM 20.1.2)\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] \n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] vertd will fall back to CPU rendering to ensure conversions can still proceed.\n[2026-01-20T14:43:41Z WARN  vertd::converter::gpu] *******\n[2026-01-20T14:43:41Z INFO  vertd] using CPU rendering (software encoding) -- this will be slower than GPU acceleration\n[2026-01-20T14:43:41Z INFO  vertd::http] http server listening on 0.0.0.0:24153\n",
  "watchtower": "time=\"2026-01-20T14:44:05Z\" level=info msg=\"Watchtower 1.7.1\"\ntime=\"2026-01-20T14:44:05Z\" level=info msg=\"Using notifications: generic+http\"\ntime=\"2026-01-20T14:44:05Z\" level=info msg=\"Checking all containers (except explicitly disabled with label)\"\ntime=\"2026-01-20T14:44:05Z\" level=info msg=\"Scheduling first run: 2026-01-20 15:44:05 +0000 UTC\"\ntime=\"2026-01-20T14:44:05Z\" level=info msg=\"Note that the first check will be performed in 59 minutes, 59 seconds\"\n",
  "invidious-db": "2026-01-20 14:43:41.096 UTC [50] LOG:  database system was shut down at 2026-01-20 14:43:39 UTC\n2026-01-20 14:43:41.101 UTC [49] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init-invidious-db.sh\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE INDEX\nCREATE TABLE\nGRANT\nCREATE TYPE\nCREATE TABLE\nGRANT\nCREATE TABLE\nGRANT\n\nwaiting for server to shut down....2026-01-20 14:43:42.229 UTC [49] LOG:  received fast shutdown request\n2026-01-20 14:43:42.232 UTC [49] LOG:  aborting any active transactions\n2026-01-20 14:43:42.235 UTC [49] LOG:  background worker \"logical replication launcher\" (PID 56) exited with exit code 1\n2026-01-20 14:43:42.235 UTC [51] LOG:  shutting down\n2026-01-20 14:43:42.279 UTC [49] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-20 14:43:42.355 UTC [1] LOG:  starting PostgreSQL 14.20 (Debian 14.20-1.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit\n2026-01-20 14:43:42.355 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-20 14:43:42.355 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-20 14:43:42.359 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-20 14:43:42.365 UTC [83] LOG:  database system was shut down at 2026-01-20 14:43:42 UTC\n2026-01-20 14:43:42.371 UTC [1] LOG:  database system is ready to accept connections\n",
  "wikiless-redis": "1:C 20 Jan 2026 14:43:42.807 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 20 Jan 2026 14:43:42.809 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 20 Jan 2026 14:43:42.809 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 20 Jan 2026 14:43:42.809 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 20 Jan 2026 14:43:42.810 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 20 Jan 2026 14:43:42.810 * monotonic clock: POSIX clock_gettime\n1:M 20 Jan 2026 14:43:42.811 * Running mode=standalone, port=6379.\n1:M 20 Jan 2026 14:43:42.811 * Server initialized\n1:M 20 Jan 2026 14:43:42.811 * Ready to accept connections tcp\n",
  "searxng-redis": "1:C 20 Jan 2026 14:43:36.739 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:C 20 Jan 2026 14:43:36.739 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 20 Jan 2026 14:43:36.739 * Redis version=7.4.7, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 20 Jan 2026 14:43:36.739 * Configuration loaded\n1:M 20 Jan 2026 14:43:36.740 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 20 Jan 2026 14:43:36.740 * monotonic clock: POSIX clock_gettime\n1:M 20 Jan 2026 14:43:36.742 * Running mode=standalone, port=6379.\n1:M 20 Jan 2026 14:43:36.743 * Server initialized\n1:M 20 Jan 2026 14:43:36.743 * Ready to accept connections tcp\n",
  "immich-db": "selecting default shared_buffers ... 128MB\nselecting default time zone ... Etc/UTC\ncreating configuration files ... ok\nrunning bootstrap script ... ok\nperforming post-bootstrap initialization ... ok\ninitdb: warning: enabling \"trust\" authentication for local connections\nYou can change this by editing pg_hba.conf or using the option -A, or\n--auth-local and --auth-host, the next time you run initdb.\nsyncing data to disk ... ok\n\n\nSuccess. You can now start the database server using:\n\n    pg_ctl -D /var/lib/postgresql/data -l logfile start\n\n2026-01-20 14:43:41.037 GMT [49] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 14:43:41.038 GMT [49] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\nwaiting for server to start....2026-01-20 14:43:41.071 GMT [54] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 14:43:41.071 GMT [54] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 14:43:41.111 UTC [54] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-20 14:43:41.113 UTC [54] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-20 14:43:41.119 UTC [55] LOG:  database system was shut down at 2026-01-20 14:43:39 UTC\n2026-01-20 14:43:41.126 UTC [54] LOG:  database system is ready to accept connections\n done\nserver started\nCREATE DATABASE\n\n\n/usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*\n\nwaiting for server to shut down....2026-01-20 14:43:41.793 UTC [54] LOG:  received fast shutdown request\n2026-01-20 14:43:41.795 UTC [54] LOG:  aborting any active transactions\n2026-01-20 14:43:41.799 UTC [54] LOG:  background worker \"logical replication launcher\" (PID 62) exited with exit code 1\n2026-01-20 14:43:41.806 UTC [57] LOG:  shutting down\n2026-01-20 14:43:41.830 UTC [54] LOG:  database system is shut down\n done\nserver stopped\n\nPostgreSQL init process complete; ready for start up.\n\n2026-01-20 14:43:41.907 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 14:43:41.908 GMT [1] LOG:  skipping missing configuration file \"/var/lib/postgresql/data/postgresql.override.conf\"\n2026-01-20 14:43:41.934 UTC [1] LOG:  starting PostgreSQL 14.19 (Debian 14.19-1.pgdg12+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14+deb12u1) 12.2.0, 64-bit\n2026-01-20 14:43:41.934 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2026-01-20 14:43:41.934 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2026-01-20 14:43:41.937 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2026-01-20 14:43:41.941 UTC [72] LOG:  database system was shut down at 2026-01-20 14:43:41 UTC\n2026-01-20 14:43:41.949 UTC [1] LOG:  database system is ready to accept connections\n2026-01-20 14:44:03.192 UTC [105] ERROR:  relation \"system_metadata\" does not exist at character 21\n2026-01-20 14:44:03.192 UTC [105] STATEMENT:  select \"value\" from \"system_metadata\" where \"key\" = $1\n",
  "immich-redis": "1:M 20 Jan 2026 14:43:37.103 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n1:M 20 Jan 2026 14:43:37.103 * oO0OoO0OoO0Oo Valkey is starting oO0OoO0OoO0Oo\n1:M 20 Jan 2026 14:43:37.103 * Valkey version=9.0.1, bits=64, commit=00000000, modified=0, pid=1, just started\n1:M 20 Jan 2026 14:43:37.103 # Warning: no config file specified, using the default config. In order to specify a config file use valkey-server /path/to/valkey.conf\n1:M 20 Jan 2026 14:43:37.104 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n1:M 20 Jan 2026 14:43:37.104 * monotonic clock: POSIX clock_gettime\n1:M 20 Jan 2026 14:43:37.105 * Running mode=standalone, port=6379.\n1:M 20 Jan 2026 14:43:37.106 * Server initialized\n1:M 20 Jan 2026 14:43:37.106 * Ready to accept connections tcp\n",
  "immich-ml": "\u001b[2;36m[01/20/26 14:43:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting gunicorn \u001b[1;36m23.0\u001b[0m.\u001b[1;36m0\u001b[0m                           \n\u001b[2;36m[01/20/26 14:43:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Listening at: \u001b[4;94mhttp://\u001b[0m\u001b[1m[\u001b[0m::\u001b[1m]\u001b[0m:\u001b[1;36m3003\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1m)\u001b[0m                \n\u001b[2;36m[01/20/26 14:43:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using worker: immich_ml.config.CustomUvicornWorker \n\u001b[2;36m[01/20/26 14:43:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Booting worker with pid: \u001b[1;36m15\u001b[0m                        \n\u001b[2;36m[01/20/26 14:44:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Started server process \u001b[1m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m                        \n\u001b[2;36m[01/20/26 14:44:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Waiting for application startup.                   \n\u001b[2;36m[01/20/26 14:44:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created in-memory cache with unloading after 300s  \n\u001b[2;36m                    \u001b[0m         of inactivity.                                     \n\u001b[2;36m[01/20/26 14:44:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialized request thread pool with \u001b[1;36m4\u001b[0m threads.    \n\u001b[2;36m[01/20/26 14:44:02]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Application startup complete.                      \n"
}